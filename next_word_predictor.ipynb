{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2s95EIHchnjfadjL3By+h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kumardhruv88/deep_learning-projects/blob/main/next_word_predictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEiNiV-K4MZm"
      },
      "outputs": [],
      "source": [
        "data=\"\"\" A machine-learning model transforms its input data into meaningful outputs, a pro\n",
        "cess that is “learned” from exposure to known examples of inputs and outputs. There\n",
        "fore, the central problem in machine learning and deep learning is to meaningfully\n",
        " transform data: in other words, to learn useful representations of the input data at\n",
        " hand—representations that get us closer to the expected output. Before we go any\n",
        " further: what’s a representation? At its core, it’s a different way to look at data—to rep\n",
        "resent or encode data. For instance, a color image can be encoded in the RGB format\n",
        " (red-green-blue) or in the HSV format (hue-saturation-value): these are two different\n",
        " representations of the same data. Some tasks that may be difficult with one represen\n",
        "tation can become easy with another. For example, the task “select all red pixels in the\n",
        " image” is simpler in the RG format, whereas “make the image less saturated” is simpler\n",
        " in the HSV format. Machine-learning models are all about finding appropriate repre\n",
        "sentations for their input data—transformations of the data that make it more amena\n",
        "ble to the task at hand, such as a classification task.  Deep learning is a specific subfield of machine learning: a new take on learning repre\n",
        "sentations from data that puts an emphasis on learning successive layers of increasingly\n",
        " meaningful representations. The deep in deep learning isn’t a reference to any kind of\n",
        " deeper understanding achieved by the approach; rather, it stands for this idea of suc\n",
        "cessive layers of representations. How many layers contribute to a model of the data is\n",
        " called the depth of the model. Other appropriate names for the field could have been\n",
        " layered representations learning and hierarchical representations learning. Modern deep\n",
        " learning often involves tens or even hundreds of successive layers of representations—\n",
        " and they’re all learned automatically from exposure to training data. Meanwhile,\n",
        " other approaches to machine learning tend to focus on learning only one or two lay\n",
        "ers of representations of the data; hence, they’re sometimes called shallow learning.\n",
        " In deep learning, these layered representations are (almost always) learned via\n",
        " models called neural networks, structured in literal layers stacked on top of each other.\n",
        " The term neural network is a reference to neurobiology, but although some of the cen\n",
        "tral concepts in deep learning were developed in part by drawing inspiration from our\n",
        " understanding of the brain, deep-learning models are not models of the brain.\n",
        " There’s no evidence that the brain implements anything like the learning mecha\n",
        "nisms used in modern deep-learning models. You may come across pop-science arti\n",
        "cles proclaiming that deep learning works like the brain or was modeled after the\n",
        " brain, but that isn’t the case. It would be confusing and counterproductive for new\n",
        "comers to the field to think of deep learning as being in any way related to neurobiol\n",
        "ogy; you don’t need that shroud of “just like our minds” mystique and mystery, and\n",
        " you may as well forget anything you may have read about hypothetical links between\n",
        " deep learning and biology. For our purposes, deep learning is a mathematical frame\n",
        "work for learning representations from data Although deep learning is a fairly old subfield of machine learning, it only rose to\n",
        " prominence in the early 2010s. In the few years since, it has achieved nothing short of\n",
        " a revolution in the field, with remarkable results on perceptual problems such as see\n",
        "ing and hearing—problems involving skills that seem natural and intuitive to humans\n",
        " but have long been elusive for machines.\n",
        " In particular, deep learning has achieved the following breakthroughs, all in his\n",
        "torically difficult areas of machine learning:\n",
        "  Near-human-level image classification\n",
        "  Near-human-level speech recognition\n",
        "  Near-human-level handwriting transcription\n",
        "  Improved machine translatio Don’t believe the short-term hype\n",
        " Although deep learning has led to remarkable achievements in recent years, expecta\n",
        "tions for what the field will be able to achieve in the next decade tend to run much\n",
        " higher than what will likely be possible. Although some world-changing applications\n",
        " like autonomous cars are already within reach, many more are likely to remain elusive\n",
        " for a long time, such as believable dialogue systems, human-level machine translation\n",
        " across arbitrary languages, and human-level natural-language understanding. In par\n",
        "ticular, talk of human-level general intelligence shouldn’t be taken too seriously. The risk\n",
        " with high expectations for the short term is that, as technology fails to deliver,\n",
        " research investment will dry up, slowing progress for a long time.\n",
        " This has happened before. Twice in the past, AI went through a cycle of intense\n",
        " optimism followed by disappointment and skepticism, with a dearth of funding as a\n",
        " result. It started with symbolic AI in the 1960s. In those early days, projections about AI\n",
        " were flying high. One of the best-known pioneers and proponents of the symbolic AI\n",
        " approach was Marvin Minsky, who claimed in 1967, “Within a generation … the prob\n",
        "lem of creating ‘artificial intelligence’ will substantially be solved.” Three years later, in\n",
        " 1970, he made a more precisely quantified prediction: “In from three to eight years we\n",
        " will have a machine with the general intelligence of an average human being.” In 2016,\n",
        " such an achievement still appears to be far in the future—so far that we have no way to\n",
        " predict how long it will take—but in the 1960s and early 1970s, several experts believed\n",
        " it to be right around the corner (as do many people today). A few years later, as these\n",
        " high expectations failed to materialize, researchers and government funds turned\n",
        " away from the field, marking the start of the first AI winter (a reference to a nuclear win\n",
        "ter, because this was shortly after the height of the Cold War).\n",
        " It wouldn’t be the last one. In the 1980s, a new take on symbolic AI, expert systems,\n",
        " started gathering steam among large companies. A few initial success stories triggered\n",
        " a wave of investment, with corporations around the world starting their own in-house\n",
        " AI departments to develop expert systems. Around 1985, companies were spending\n",
        " over $1 billion each year on the technology; but by the early 1990s, these systems had\n",
        " proven expensive to maintain, difficult to scale\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n"
      ],
      "metadata": {
        "id": "VQFLBRwQ4q8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=Tokenizer()"
      ],
      "metadata": {
        "id": "ucnJIVFv6JUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts([data])"
      ],
      "metadata": {
        "id": "wLvgogob6OEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3YE3R6q6V6t",
        "outputId": "903eda5e-c0a5-414a-c9ce-b10214386dcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'the': 1,\n",
              " 'of': 2,\n",
              " 'in': 3,\n",
              " 'to': 4,\n",
              " 'learning': 5,\n",
              " 'a': 6,\n",
              " 'deep': 7,\n",
              " 'and': 8,\n",
              " 'for': 9,\n",
              " 'that': 10,\n",
              " 'data': 11,\n",
              " 'machine': 12,\n",
              " 'is': 13,\n",
              " 'be': 14,\n",
              " 'representations': 15,\n",
              " 'it': 16,\n",
              " 'as': 17,\n",
              " 'with': 18,\n",
              " 'from': 19,\n",
              " 'on': 20,\n",
              " 'human': 21,\n",
              " 'ai': 22,\n",
              " 'are': 23,\n",
              " 'level': 24,\n",
              " 'will': 25,\n",
              " 'or': 26,\n",
              " 'models': 27,\n",
              " 'layers': 28,\n",
              " 'field': 29,\n",
              " 'have': 30,\n",
              " 'brain': 31,\n",
              " 'years': 32,\n",
              " 'other': 33,\n",
              " 'at': 34,\n",
              " 'format': 35,\n",
              " 'these': 36,\n",
              " 'may': 37,\n",
              " 'one': 38,\n",
              " 'all': 39,\n",
              " 'such': 40,\n",
              " 'by': 41,\n",
              " 'but': 42,\n",
              " 'although': 43,\n",
              " 'like': 44,\n",
              " 'you': 45,\n",
              " 'early': 46,\n",
              " 'has': 47,\n",
              " 'long': 48,\n",
              " '\\uf0a1': 49,\n",
              " 'systems': 50,\n",
              " 'model': 51,\n",
              " 'input': 52,\n",
              " 'we': 53,\n",
              " 'any': 54,\n",
              " 'way': 55,\n",
              " 'image': 56,\n",
              " 'some': 57,\n",
              " 'difficult': 58,\n",
              " 'task': 59,\n",
              " 'about': 60,\n",
              " 'more': 61,\n",
              " 'new': 62,\n",
              " 'an': 63,\n",
              " 'reference': 64,\n",
              " 'understanding': 65,\n",
              " 'achieved': 66,\n",
              " 'this': 67,\n",
              " 'many': 68,\n",
              " 'called': 69,\n",
              " 'term': 70,\n",
              " 'were': 71,\n",
              " 'our': 72,\n",
              " 'was': 73,\n",
              " 'few': 74,\n",
              " 'short': 75,\n",
              " 'near': 76,\n",
              " 'high': 77,\n",
              " 'symbolic': 78,\n",
              " 'around': 79,\n",
              " 'its': 80,\n",
              " 'meaningful': 81,\n",
              " 'outputs': 82,\n",
              " 'exposure': 83,\n",
              " 'known': 84,\n",
              " 'before': 85,\n",
              " 'different': 86,\n",
              " 'can': 87,\n",
              " 'red': 88,\n",
              " 'hsv': 89,\n",
              " 'two': 90,\n",
              " 'simpler': 91,\n",
              " 'appropriate': 92,\n",
              " 'repre': 93,\n",
              " 'sentations': 94,\n",
              " 'their': 95,\n",
              " 'classification': 96,\n",
              " 'subfield': 97,\n",
              " 'take': 98,\n",
              " 'successive': 99,\n",
              " 'isn’t': 100,\n",
              " 'approach': 101,\n",
              " 'how': 102,\n",
              " 'been': 103,\n",
              " 'layered': 104,\n",
              " 'modern': 105,\n",
              " 'they’re': 106,\n",
              " 'learned': 107,\n",
              " 'tend': 108,\n",
              " 'only': 109,\n",
              " 'neural': 110,\n",
              " 'each': 111,\n",
              " 'no': 112,\n",
              " 'anything': 113,\n",
              " 'across': 114,\n",
              " 'after': 115,\n",
              " 'being': 116,\n",
              " 'don’t': 117,\n",
              " 'remarkable': 118,\n",
              " 'natural': 119,\n",
              " 'elusive': 120,\n",
              " 'what': 121,\n",
              " 'likely': 122,\n",
              " 'world': 123,\n",
              " 'time': 124,\n",
              " 'general': 125,\n",
              " 'intelligence': 126,\n",
              " 'expectations': 127,\n",
              " 'technology': 128,\n",
              " 'investment': 129,\n",
              " 'started': 130,\n",
              " '1960s': 131,\n",
              " '”': 132,\n",
              " 'three': 133,\n",
              " 'later': 134,\n",
              " 'far': 135,\n",
              " 'expert': 136,\n",
              " 'companies': 137,\n",
              " 'transforms': 138,\n",
              " 'into': 139,\n",
              " 'pro': 140,\n",
              " 'cess': 141,\n",
              " '“learned”': 142,\n",
              " 'examples': 143,\n",
              " 'inputs': 144,\n",
              " 'there': 145,\n",
              " 'fore': 146,\n",
              " 'central': 147,\n",
              " 'problem': 148,\n",
              " 'meaningfully': 149,\n",
              " 'transform': 150,\n",
              " 'words': 151,\n",
              " 'learn': 152,\n",
              " 'useful': 153,\n",
              " 'hand—representations': 154,\n",
              " 'get': 155,\n",
              " 'us': 156,\n",
              " 'closer': 157,\n",
              " 'expected': 158,\n",
              " 'output': 159,\n",
              " 'go': 160,\n",
              " 'further': 161,\n",
              " 'what’s': 162,\n",
              " 'representation': 163,\n",
              " 'core': 164,\n",
              " 'it’s': 165,\n",
              " 'look': 166,\n",
              " 'data—to': 167,\n",
              " 'rep': 168,\n",
              " 'resent': 169,\n",
              " 'encode': 170,\n",
              " 'instance': 171,\n",
              " 'color': 172,\n",
              " 'encoded': 173,\n",
              " 'rgb': 174,\n",
              " 'green': 175,\n",
              " 'blue': 176,\n",
              " 'hue': 177,\n",
              " 'saturation': 178,\n",
              " 'value': 179,\n",
              " 'same': 180,\n",
              " 'tasks': 181,\n",
              " 'represen': 182,\n",
              " 'tation': 183,\n",
              " 'become': 184,\n",
              " 'easy': 185,\n",
              " 'another': 186,\n",
              " 'example': 187,\n",
              " '“select': 188,\n",
              " 'pixels': 189,\n",
              " 'image”': 190,\n",
              " 'rg': 191,\n",
              " 'whereas': 192,\n",
              " '“make': 193,\n",
              " 'less': 194,\n",
              " 'saturated”': 195,\n",
              " 'finding': 196,\n",
              " 'data—transformations': 197,\n",
              " 'make': 198,\n",
              " 'amena': 199,\n",
              " 'ble': 200,\n",
              " 'hand': 201,\n",
              " 'specific': 202,\n",
              " 'puts': 203,\n",
              " 'emphasis': 204,\n",
              " 'increasingly': 205,\n",
              " 'kind': 206,\n",
              " 'deeper': 207,\n",
              " 'rather': 208,\n",
              " 'stands': 209,\n",
              " 'idea': 210,\n",
              " 'suc': 211,\n",
              " 'cessive': 212,\n",
              " 'contribute': 213,\n",
              " 'depth': 214,\n",
              " 'names': 215,\n",
              " 'could': 216,\n",
              " 'hierarchical': 217,\n",
              " 'often': 218,\n",
              " 'involves': 219,\n",
              " 'tens': 220,\n",
              " 'even': 221,\n",
              " 'hundreds': 222,\n",
              " 'representations—': 223,\n",
              " 'automatically': 224,\n",
              " 'training': 225,\n",
              " 'meanwhile': 226,\n",
              " 'approaches': 227,\n",
              " 'focus': 228,\n",
              " 'lay': 229,\n",
              " 'ers': 230,\n",
              " 'hence': 231,\n",
              " 'sometimes': 232,\n",
              " 'shallow': 233,\n",
              " 'almost': 234,\n",
              " 'always': 235,\n",
              " 'via': 236,\n",
              " 'networks': 237,\n",
              " 'structured': 238,\n",
              " 'literal': 239,\n",
              " 'stacked': 240,\n",
              " 'top': 241,\n",
              " 'network': 242,\n",
              " 'neurobiology': 243,\n",
              " 'cen': 244,\n",
              " 'tral': 245,\n",
              " 'concepts': 246,\n",
              " 'developed': 247,\n",
              " 'part': 248,\n",
              " 'drawing': 249,\n",
              " 'inspiration': 250,\n",
              " 'not': 251,\n",
              " 'there’s': 252,\n",
              " 'evidence': 253,\n",
              " 'implements': 254,\n",
              " 'mecha': 255,\n",
              " 'nisms': 256,\n",
              " 'used': 257,\n",
              " 'come': 258,\n",
              " 'pop': 259,\n",
              " 'science': 260,\n",
              " 'arti': 261,\n",
              " 'cles': 262,\n",
              " 'proclaiming': 263,\n",
              " 'works': 264,\n",
              " 'modeled': 265,\n",
              " 'case': 266,\n",
              " 'would': 267,\n",
              " 'confusing': 268,\n",
              " 'counterproductive': 269,\n",
              " 'comers': 270,\n",
              " 'think': 271,\n",
              " 'related': 272,\n",
              " 'neurobiol': 273,\n",
              " 'ogy': 274,\n",
              " 'need': 275,\n",
              " 'shroud': 276,\n",
              " '“just': 277,\n",
              " 'minds”': 278,\n",
              " 'mystique': 279,\n",
              " 'mystery': 280,\n",
              " 'well': 281,\n",
              " 'forget': 282,\n",
              " 'read': 283,\n",
              " 'hypothetical': 284,\n",
              " 'links': 285,\n",
              " 'between': 286,\n",
              " 'biology': 287,\n",
              " 'purposes': 288,\n",
              " 'mathematical': 289,\n",
              " 'frame': 290,\n",
              " 'work': 291,\n",
              " 'fairly': 292,\n",
              " 'old': 293,\n",
              " 'rose': 294,\n",
              " 'prominence': 295,\n",
              " '2010s': 296,\n",
              " 'since': 297,\n",
              " 'nothing': 298,\n",
              " 'revolution': 299,\n",
              " 'results': 300,\n",
              " 'perceptual': 301,\n",
              " 'problems': 302,\n",
              " 'see': 303,\n",
              " 'ing': 304,\n",
              " 'hearing—problems': 305,\n",
              " 'involving': 306,\n",
              " 'skills': 307,\n",
              " 'seem': 308,\n",
              " 'intuitive': 309,\n",
              " 'humans': 310,\n",
              " 'machines': 311,\n",
              " 'particular': 312,\n",
              " 'following': 313,\n",
              " 'breakthroughs': 314,\n",
              " 'his': 315,\n",
              " 'torically': 316,\n",
              " 'areas': 317,\n",
              " 'speech': 318,\n",
              " 'recognition': 319,\n",
              " 'handwriting': 320,\n",
              " 'transcription': 321,\n",
              " 'improved': 322,\n",
              " 'translatio': 323,\n",
              " 'believe': 324,\n",
              " 'hype': 325,\n",
              " 'led': 326,\n",
              " 'achievements': 327,\n",
              " 'recent': 328,\n",
              " 'expecta': 329,\n",
              " 'tions': 330,\n",
              " 'able': 331,\n",
              " 'achieve': 332,\n",
              " 'next': 333,\n",
              " 'decade': 334,\n",
              " 'run': 335,\n",
              " 'much': 336,\n",
              " 'higher': 337,\n",
              " 'than': 338,\n",
              " 'possible': 339,\n",
              " 'changing': 340,\n",
              " 'applications': 341,\n",
              " 'autonomous': 342,\n",
              " 'cars': 343,\n",
              " 'already': 344,\n",
              " 'within': 345,\n",
              " 'reach': 346,\n",
              " 'remain': 347,\n",
              " 'believable': 348,\n",
              " 'dialogue': 349,\n",
              " 'translation': 350,\n",
              " 'arbitrary': 351,\n",
              " 'languages': 352,\n",
              " 'language': 353,\n",
              " 'par': 354,\n",
              " 'ticular': 355,\n",
              " 'talk': 356,\n",
              " 'shouldn’t': 357,\n",
              " 'taken': 358,\n",
              " 'too': 359,\n",
              " 'seriously': 360,\n",
              " 'risk': 361,\n",
              " 'fails': 362,\n",
              " 'deliver': 363,\n",
              " 'research': 364,\n",
              " 'dry': 365,\n",
              " 'up': 366,\n",
              " 'slowing': 367,\n",
              " 'progress': 368,\n",
              " 'happened': 369,\n",
              " 'twice': 370,\n",
              " 'past': 371,\n",
              " 'went': 372,\n",
              " 'through': 373,\n",
              " 'cycle': 374,\n",
              " 'intense': 375,\n",
              " 'optimism': 376,\n",
              " 'followed': 377,\n",
              " 'disappointment': 378,\n",
              " 'skepticism': 379,\n",
              " 'dearth': 380,\n",
              " 'funding': 381,\n",
              " 'result': 382,\n",
              " 'those': 383,\n",
              " 'days': 384,\n",
              " 'projections': 385,\n",
              " 'flying': 386,\n",
              " 'best': 387,\n",
              " 'pioneers': 388,\n",
              " 'proponents': 389,\n",
              " 'marvin': 390,\n",
              " 'minsky': 391,\n",
              " 'who': 392,\n",
              " 'claimed': 393,\n",
              " '1967': 394,\n",
              " '“within': 395,\n",
              " 'generation': 396,\n",
              " '…': 397,\n",
              " 'prob': 398,\n",
              " 'lem': 399,\n",
              " 'creating': 400,\n",
              " '‘artificial': 401,\n",
              " 'intelligence’': 402,\n",
              " 'substantially': 403,\n",
              " 'solved': 404,\n",
              " '1970': 405,\n",
              " 'he': 406,\n",
              " 'made': 407,\n",
              " 'precisely': 408,\n",
              " 'quantified': 409,\n",
              " 'prediction': 410,\n",
              " '“in': 411,\n",
              " 'eight': 412,\n",
              " 'average': 413,\n",
              " '2016': 414,\n",
              " 'achievement': 415,\n",
              " 'still': 416,\n",
              " 'appears': 417,\n",
              " 'future—so': 418,\n",
              " 'predict': 419,\n",
              " 'take—but': 420,\n",
              " '1970s': 421,\n",
              " 'several': 422,\n",
              " 'experts': 423,\n",
              " 'believed': 424,\n",
              " 'right': 425,\n",
              " 'corner': 426,\n",
              " 'do': 427,\n",
              " 'people': 428,\n",
              " 'today': 429,\n",
              " 'failed': 430,\n",
              " 'materialize': 431,\n",
              " 'researchers': 432,\n",
              " 'government': 433,\n",
              " 'funds': 434,\n",
              " 'turned': 435,\n",
              " 'away': 436,\n",
              " 'marking': 437,\n",
              " 'start': 438,\n",
              " 'first': 439,\n",
              " 'winter': 440,\n",
              " 'nuclear': 441,\n",
              " 'win': 442,\n",
              " 'ter': 443,\n",
              " 'because': 444,\n",
              " 'shortly': 445,\n",
              " 'height': 446,\n",
              " 'cold': 447,\n",
              " 'war': 448,\n",
              " 'wouldn’t': 449,\n",
              " 'last': 450,\n",
              " '1980s': 451,\n",
              " 'gathering': 452,\n",
              " 'steam': 453,\n",
              " 'among': 454,\n",
              " 'large': 455,\n",
              " 'initial': 456,\n",
              " 'success': 457,\n",
              " 'stories': 458,\n",
              " 'triggered': 459,\n",
              " 'wave': 460,\n",
              " 'corporations': 461,\n",
              " 'starting': 462,\n",
              " 'own': 463,\n",
              " 'house': 464,\n",
              " 'departments': 465,\n",
              " 'develop': 466,\n",
              " '1985': 467,\n",
              " 'spending': 468,\n",
              " 'over': 469,\n",
              " '1': 470,\n",
              " 'billion': 471,\n",
              " 'year': 472,\n",
              " '1990s': 473,\n",
              " 'had': 474,\n",
              " 'proven': 475,\n",
              " 'expensive': 476,\n",
              " 'maintain': 477,\n",
              " 'scale': 478}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences=[]\n",
        "for sentences in data.split('\\n'):\n",
        "  tokenise_sentence=tokenizer.texts_to_sequences([sentences])[0]\n",
        "\n",
        "  for i in range(1,len(tokenise_sentence)):\n",
        "    input_sequences.append(tokenise_sentence[:i+1])\n",
        "\n"
      ],
      "metadata": {
        "id": "KalEwqsF6cUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nUBIynY61Js",
        "outputId": "d014af1b-646b-4a9b-a907-3153742b09d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[6, 12],\n",
              " [6, 12, 5],\n",
              " [6, 12, 5, 51],\n",
              " [6, 12, 5, 51, 138],\n",
              " [6, 12, 5, 51, 138, 80],\n",
              " [6, 12, 5, 51, 138, 80, 52],\n",
              " [6, 12, 5, 51, 138, 80, 52, 11],\n",
              " [6, 12, 5, 51, 138, 80, 52, 11, 139],\n",
              " [6, 12, 5, 51, 138, 80, 52, 11, 139, 81],\n",
              " [6, 12, 5, 51, 138, 80, 52, 11, 139, 81, 82],\n",
              " [6, 12, 5, 51, 138, 80, 52, 11, 139, 81, 82, 6],\n",
              " [6, 12, 5, 51, 138, 80, 52, 11, 139, 81, 82, 6, 140],\n",
              " [141, 10],\n",
              " [141, 10, 13],\n",
              " [141, 10, 13, 142],\n",
              " [141, 10, 13, 142, 19],\n",
              " [141, 10, 13, 142, 19, 83],\n",
              " [141, 10, 13, 142, 19, 83, 4],\n",
              " [141, 10, 13, 142, 19, 83, 4, 84],\n",
              " [141, 10, 13, 142, 19, 83, 4, 84, 143],\n",
              " [141, 10, 13, 142, 19, 83, 4, 84, 143, 2],\n",
              " [141, 10, 13, 142, 19, 83, 4, 84, 143, 2, 144],\n",
              " [141, 10, 13, 142, 19, 83, 4, 84, 143, 2, 144, 8],\n",
              " [141, 10, 13, 142, 19, 83, 4, 84, 143, 2, 144, 8, 82],\n",
              " [141, 10, 13, 142, 19, 83, 4, 84, 143, 2, 144, 8, 82, 145],\n",
              " [146, 1],\n",
              " [146, 1, 147],\n",
              " [146, 1, 147, 148],\n",
              " [146, 1, 147, 148, 3],\n",
              " [146, 1, 147, 148, 3, 12],\n",
              " [146, 1, 147, 148, 3, 12, 5],\n",
              " [146, 1, 147, 148, 3, 12, 5, 8],\n",
              " [146, 1, 147, 148, 3, 12, 5, 8, 7],\n",
              " [146, 1, 147, 148, 3, 12, 5, 8, 7, 5],\n",
              " [146, 1, 147, 148, 3, 12, 5, 8, 7, 5, 13],\n",
              " [146, 1, 147, 148, 3, 12, 5, 8, 7, 5, 13, 4],\n",
              " [146, 1, 147, 148, 3, 12, 5, 8, 7, 5, 13, 4, 149],\n",
              " [150, 11],\n",
              " [150, 11, 3],\n",
              " [150, 11, 3, 33],\n",
              " [150, 11, 3, 33, 151],\n",
              " [150, 11, 3, 33, 151, 4],\n",
              " [150, 11, 3, 33, 151, 4, 152],\n",
              " [150, 11, 3, 33, 151, 4, 152, 153],\n",
              " [150, 11, 3, 33, 151, 4, 152, 153, 15],\n",
              " [150, 11, 3, 33, 151, 4, 152, 153, 15, 2],\n",
              " [150, 11, 3, 33, 151, 4, 152, 153, 15, 2, 1],\n",
              " [150, 11, 3, 33, 151, 4, 152, 153, 15, 2, 1, 52],\n",
              " [150, 11, 3, 33, 151, 4, 152, 153, 15, 2, 1, 52, 11],\n",
              " [150, 11, 3, 33, 151, 4, 152, 153, 15, 2, 1, 52, 11, 34],\n",
              " [154, 10],\n",
              " [154, 10, 155],\n",
              " [154, 10, 155, 156],\n",
              " [154, 10, 155, 156, 157],\n",
              " [154, 10, 155, 156, 157, 4],\n",
              " [154, 10, 155, 156, 157, 4, 1],\n",
              " [154, 10, 155, 156, 157, 4, 1, 158],\n",
              " [154, 10, 155, 156, 157, 4, 1, 158, 159],\n",
              " [154, 10, 155, 156, 157, 4, 1, 158, 159, 85],\n",
              " [154, 10, 155, 156, 157, 4, 1, 158, 159, 85, 53],\n",
              " [154, 10, 155, 156, 157, 4, 1, 158, 159, 85, 53, 160],\n",
              " [154, 10, 155, 156, 157, 4, 1, 158, 159, 85, 53, 160, 54],\n",
              " [161, 162],\n",
              " [161, 162, 6],\n",
              " [161, 162, 6, 163],\n",
              " [161, 162, 6, 163, 34],\n",
              " [161, 162, 6, 163, 34, 80],\n",
              " [161, 162, 6, 163, 34, 80, 164],\n",
              " [161, 162, 6, 163, 34, 80, 164, 165],\n",
              " [161, 162, 6, 163, 34, 80, 164, 165, 6],\n",
              " [161, 162, 6, 163, 34, 80, 164, 165, 6, 86],\n",
              " [161, 162, 6, 163, 34, 80, 164, 165, 6, 86, 55],\n",
              " [161, 162, 6, 163, 34, 80, 164, 165, 6, 86, 55, 4],\n",
              " [161, 162, 6, 163, 34, 80, 164, 165, 6, 86, 55, 4, 166],\n",
              " [161, 162, 6, 163, 34, 80, 164, 165, 6, 86, 55, 4, 166, 34],\n",
              " [161, 162, 6, 163, 34, 80, 164, 165, 6, 86, 55, 4, 166, 34, 167],\n",
              " [161, 162, 6, 163, 34, 80, 164, 165, 6, 86, 55, 4, 166, 34, 167, 168],\n",
              " [169, 26],\n",
              " [169, 26, 170],\n",
              " [169, 26, 170, 11],\n",
              " [169, 26, 170, 11, 9],\n",
              " [169, 26, 170, 11, 9, 171],\n",
              " [169, 26, 170, 11, 9, 171, 6],\n",
              " [169, 26, 170, 11, 9, 171, 6, 172],\n",
              " [169, 26, 170, 11, 9, 171, 6, 172, 56],\n",
              " [169, 26, 170, 11, 9, 171, 6, 172, 56, 87],\n",
              " [169, 26, 170, 11, 9, 171, 6, 172, 56, 87, 14],\n",
              " [169, 26, 170, 11, 9, 171, 6, 172, 56, 87, 14, 173],\n",
              " [169, 26, 170, 11, 9, 171, 6, 172, 56, 87, 14, 173, 3],\n",
              " [169, 26, 170, 11, 9, 171, 6, 172, 56, 87, 14, 173, 3, 1],\n",
              " [169, 26, 170, 11, 9, 171, 6, 172, 56, 87, 14, 173, 3, 1, 174],\n",
              " [169, 26, 170, 11, 9, 171, 6, 172, 56, 87, 14, 173, 3, 1, 174, 35],\n",
              " [88, 175],\n",
              " [88, 175, 176],\n",
              " [88, 175, 176, 26],\n",
              " [88, 175, 176, 26, 3],\n",
              " [88, 175, 176, 26, 3, 1],\n",
              " [88, 175, 176, 26, 3, 1, 89],\n",
              " [88, 175, 176, 26, 3, 1, 89, 35],\n",
              " [88, 175, 176, 26, 3, 1, 89, 35, 177],\n",
              " [88, 175, 176, 26, 3, 1, 89, 35, 177, 178],\n",
              " [88, 175, 176, 26, 3, 1, 89, 35, 177, 178, 179],\n",
              " [88, 175, 176, 26, 3, 1, 89, 35, 177, 178, 179, 36],\n",
              " [88, 175, 176, 26, 3, 1, 89, 35, 177, 178, 179, 36, 23],\n",
              " [88, 175, 176, 26, 3, 1, 89, 35, 177, 178, 179, 36, 23, 90],\n",
              " [88, 175, 176, 26, 3, 1, 89, 35, 177, 178, 179, 36, 23, 90, 86],\n",
              " [15, 2],\n",
              " [15, 2, 1],\n",
              " [15, 2, 1, 180],\n",
              " [15, 2, 1, 180, 11],\n",
              " [15, 2, 1, 180, 11, 57],\n",
              " [15, 2, 1, 180, 11, 57, 181],\n",
              " [15, 2, 1, 180, 11, 57, 181, 10],\n",
              " [15, 2, 1, 180, 11, 57, 181, 10, 37],\n",
              " [15, 2, 1, 180, 11, 57, 181, 10, 37, 14],\n",
              " [15, 2, 1, 180, 11, 57, 181, 10, 37, 14, 58],\n",
              " [15, 2, 1, 180, 11, 57, 181, 10, 37, 14, 58, 18],\n",
              " [15, 2, 1, 180, 11, 57, 181, 10, 37, 14, 58, 18, 38],\n",
              " [15, 2, 1, 180, 11, 57, 181, 10, 37, 14, 58, 18, 38, 182],\n",
              " [183, 87],\n",
              " [183, 87, 184],\n",
              " [183, 87, 184, 185],\n",
              " [183, 87, 184, 185, 18],\n",
              " [183, 87, 184, 185, 18, 186],\n",
              " [183, 87, 184, 185, 18, 186, 9],\n",
              " [183, 87, 184, 185, 18, 186, 9, 187],\n",
              " [183, 87, 184, 185, 18, 186, 9, 187, 1],\n",
              " [183, 87, 184, 185, 18, 186, 9, 187, 1, 59],\n",
              " [183, 87, 184, 185, 18, 186, 9, 187, 1, 59, 188],\n",
              " [183, 87, 184, 185, 18, 186, 9, 187, 1, 59, 188, 39],\n",
              " [183, 87, 184, 185, 18, 186, 9, 187, 1, 59, 188, 39, 88],\n",
              " [183, 87, 184, 185, 18, 186, 9, 187, 1, 59, 188, 39, 88, 189],\n",
              " [183, 87, 184, 185, 18, 186, 9, 187, 1, 59, 188, 39, 88, 189, 3],\n",
              " [183, 87, 184, 185, 18, 186, 9, 187, 1, 59, 188, 39, 88, 189, 3, 1],\n",
              " [190, 13],\n",
              " [190, 13, 91],\n",
              " [190, 13, 91, 3],\n",
              " [190, 13, 91, 3, 1],\n",
              " [190, 13, 91, 3, 1, 191],\n",
              " [190, 13, 91, 3, 1, 191, 35],\n",
              " [190, 13, 91, 3, 1, 191, 35, 192],\n",
              " [190, 13, 91, 3, 1, 191, 35, 192, 193],\n",
              " [190, 13, 91, 3, 1, 191, 35, 192, 193, 1],\n",
              " [190, 13, 91, 3, 1, 191, 35, 192, 193, 1, 56],\n",
              " [190, 13, 91, 3, 1, 191, 35, 192, 193, 1, 56, 194],\n",
              " [190, 13, 91, 3, 1, 191, 35, 192, 193, 1, 56, 194, 195],\n",
              " [190, 13, 91, 3, 1, 191, 35, 192, 193, 1, 56, 194, 195, 13],\n",
              " [190, 13, 91, 3, 1, 191, 35, 192, 193, 1, 56, 194, 195, 13, 91],\n",
              " [3, 1],\n",
              " [3, 1, 89],\n",
              " [3, 1, 89, 35],\n",
              " [3, 1, 89, 35, 12],\n",
              " [3, 1, 89, 35, 12, 5],\n",
              " [3, 1, 89, 35, 12, 5, 27],\n",
              " [3, 1, 89, 35, 12, 5, 27, 23],\n",
              " [3, 1, 89, 35, 12, 5, 27, 23, 39],\n",
              " [3, 1, 89, 35, 12, 5, 27, 23, 39, 60],\n",
              " [3, 1, 89, 35, 12, 5, 27, 23, 39, 60, 196],\n",
              " [3, 1, 89, 35, 12, 5, 27, 23, 39, 60, 196, 92],\n",
              " [3, 1, 89, 35, 12, 5, 27, 23, 39, 60, 196, 92, 93],\n",
              " [94, 9],\n",
              " [94, 9, 95],\n",
              " [94, 9, 95, 52],\n",
              " [94, 9, 95, 52, 197],\n",
              " [94, 9, 95, 52, 197, 2],\n",
              " [94, 9, 95, 52, 197, 2, 1],\n",
              " [94, 9, 95, 52, 197, 2, 1, 11],\n",
              " [94, 9, 95, 52, 197, 2, 1, 11, 10],\n",
              " [94, 9, 95, 52, 197, 2, 1, 11, 10, 198],\n",
              " [94, 9, 95, 52, 197, 2, 1, 11, 10, 198, 16],\n",
              " [94, 9, 95, 52, 197, 2, 1, 11, 10, 198, 16, 61],\n",
              " [94, 9, 95, 52, 197, 2, 1, 11, 10, 198, 16, 61, 199],\n",
              " [200, 4],\n",
              " [200, 4, 1],\n",
              " [200, 4, 1, 59],\n",
              " [200, 4, 1, 59, 34],\n",
              " [200, 4, 1, 59, 34, 201],\n",
              " [200, 4, 1, 59, 34, 201, 40],\n",
              " [200, 4, 1, 59, 34, 201, 40, 17],\n",
              " [200, 4, 1, 59, 34, 201, 40, 17, 6],\n",
              " [200, 4, 1, 59, 34, 201, 40, 17, 6, 96],\n",
              " [200, 4, 1, 59, 34, 201, 40, 17, 6, 96, 59],\n",
              " [200, 4, 1, 59, 34, 201, 40, 17, 6, 96, 59, 7],\n",
              " [200, 4, 1, 59, 34, 201, 40, 17, 6, 96, 59, 7, 5],\n",
              " [200, 4, 1, 59, 34, 201, 40, 17, 6, 96, 59, 7, 5, 13],\n",
              " [200, 4, 1, 59, 34, 201, 40, 17, 6, 96, 59, 7, 5, 13, 6],\n",
              " [200, 4, 1, 59, 34, 201, 40, 17, 6, 96, 59, 7, 5, 13, 6, 202],\n",
              " [200, 4, 1, 59, 34, 201, 40, 17, 6, 96, 59, 7, 5, 13, 6, 202, 97],\n",
              " [200, 4, 1, 59, 34, 201, 40, 17, 6, 96, 59, 7, 5, 13, 6, 202, 97, 2],\n",
              " [200, 4, 1, 59, 34, 201, 40, 17, 6, 96, 59, 7, 5, 13, 6, 202, 97, 2, 12],\n",
              " [200, 4, 1, 59, 34, 201, 40, 17, 6, 96, 59, 7, 5, 13, 6, 202, 97, 2, 12, 5],\n",
              " [200,\n",
              "  4,\n",
              "  1,\n",
              "  59,\n",
              "  34,\n",
              "  201,\n",
              "  40,\n",
              "  17,\n",
              "  6,\n",
              "  96,\n",
              "  59,\n",
              "  7,\n",
              "  5,\n",
              "  13,\n",
              "  6,\n",
              "  202,\n",
              "  97,\n",
              "  2,\n",
              "  12,\n",
              "  5,\n",
              "  6],\n",
              " [200,\n",
              "  4,\n",
              "  1,\n",
              "  59,\n",
              "  34,\n",
              "  201,\n",
              "  40,\n",
              "  17,\n",
              "  6,\n",
              "  96,\n",
              "  59,\n",
              "  7,\n",
              "  5,\n",
              "  13,\n",
              "  6,\n",
              "  202,\n",
              "  97,\n",
              "  2,\n",
              "  12,\n",
              "  5,\n",
              "  6,\n",
              "  62],\n",
              " [200,\n",
              "  4,\n",
              "  1,\n",
              "  59,\n",
              "  34,\n",
              "  201,\n",
              "  40,\n",
              "  17,\n",
              "  6,\n",
              "  96,\n",
              "  59,\n",
              "  7,\n",
              "  5,\n",
              "  13,\n",
              "  6,\n",
              "  202,\n",
              "  97,\n",
              "  2,\n",
              "  12,\n",
              "  5,\n",
              "  6,\n",
              "  62,\n",
              "  98],\n",
              " [200,\n",
              "  4,\n",
              "  1,\n",
              "  59,\n",
              "  34,\n",
              "  201,\n",
              "  40,\n",
              "  17,\n",
              "  6,\n",
              "  96,\n",
              "  59,\n",
              "  7,\n",
              "  5,\n",
              "  13,\n",
              "  6,\n",
              "  202,\n",
              "  97,\n",
              "  2,\n",
              "  12,\n",
              "  5,\n",
              "  6,\n",
              "  62,\n",
              "  98,\n",
              "  20],\n",
              " [200,\n",
              "  4,\n",
              "  1,\n",
              "  59,\n",
              "  34,\n",
              "  201,\n",
              "  40,\n",
              "  17,\n",
              "  6,\n",
              "  96,\n",
              "  59,\n",
              "  7,\n",
              "  5,\n",
              "  13,\n",
              "  6,\n",
              "  202,\n",
              "  97,\n",
              "  2,\n",
              "  12,\n",
              "  5,\n",
              "  6,\n",
              "  62,\n",
              "  98,\n",
              "  20,\n",
              "  5],\n",
              " [200,\n",
              "  4,\n",
              "  1,\n",
              "  59,\n",
              "  34,\n",
              "  201,\n",
              "  40,\n",
              "  17,\n",
              "  6,\n",
              "  96,\n",
              "  59,\n",
              "  7,\n",
              "  5,\n",
              "  13,\n",
              "  6,\n",
              "  202,\n",
              "  97,\n",
              "  2,\n",
              "  12,\n",
              "  5,\n",
              "  6,\n",
              "  62,\n",
              "  98,\n",
              "  20,\n",
              "  5,\n",
              "  93],\n",
              " [94, 19],\n",
              " [94, 19, 11],\n",
              " [94, 19, 11, 10],\n",
              " [94, 19, 11, 10, 203],\n",
              " [94, 19, 11, 10, 203, 63],\n",
              " [94, 19, 11, 10, 203, 63, 204],\n",
              " [94, 19, 11, 10, 203, 63, 204, 20],\n",
              " [94, 19, 11, 10, 203, 63, 204, 20, 5],\n",
              " [94, 19, 11, 10, 203, 63, 204, 20, 5, 99],\n",
              " [94, 19, 11, 10, 203, 63, 204, 20, 5, 99, 28],\n",
              " [94, 19, 11, 10, 203, 63, 204, 20, 5, 99, 28, 2],\n",
              " [94, 19, 11, 10, 203, 63, 204, 20, 5, 99, 28, 2, 205],\n",
              " [81, 15],\n",
              " [81, 15, 1],\n",
              " [81, 15, 1, 7],\n",
              " [81, 15, 1, 7, 3],\n",
              " [81, 15, 1, 7, 3, 7],\n",
              " [81, 15, 1, 7, 3, 7, 5],\n",
              " [81, 15, 1, 7, 3, 7, 5, 100],\n",
              " [81, 15, 1, 7, 3, 7, 5, 100, 6],\n",
              " [81, 15, 1, 7, 3, 7, 5, 100, 6, 64],\n",
              " [81, 15, 1, 7, 3, 7, 5, 100, 6, 64, 4],\n",
              " [81, 15, 1, 7, 3, 7, 5, 100, 6, 64, 4, 54],\n",
              " [81, 15, 1, 7, 3, 7, 5, 100, 6, 64, 4, 54, 206],\n",
              " [81, 15, 1, 7, 3, 7, 5, 100, 6, 64, 4, 54, 206, 2],\n",
              " [207, 65],\n",
              " [207, 65, 66],\n",
              " [207, 65, 66, 41],\n",
              " [207, 65, 66, 41, 1],\n",
              " [207, 65, 66, 41, 1, 101],\n",
              " [207, 65, 66, 41, 1, 101, 208],\n",
              " [207, 65, 66, 41, 1, 101, 208, 16],\n",
              " [207, 65, 66, 41, 1, 101, 208, 16, 209],\n",
              " [207, 65, 66, 41, 1, 101, 208, 16, 209, 9],\n",
              " [207, 65, 66, 41, 1, 101, 208, 16, 209, 9, 67],\n",
              " [207, 65, 66, 41, 1, 101, 208, 16, 209, 9, 67, 210],\n",
              " [207, 65, 66, 41, 1, 101, 208, 16, 209, 9, 67, 210, 2],\n",
              " [207, 65, 66, 41, 1, 101, 208, 16, 209, 9, 67, 210, 2, 211],\n",
              " [212, 28],\n",
              " [212, 28, 2],\n",
              " [212, 28, 2, 15],\n",
              " [212, 28, 2, 15, 102],\n",
              " [212, 28, 2, 15, 102, 68],\n",
              " [212, 28, 2, 15, 102, 68, 28],\n",
              " [212, 28, 2, 15, 102, 68, 28, 213],\n",
              " [212, 28, 2, 15, 102, 68, 28, 213, 4],\n",
              " [212, 28, 2, 15, 102, 68, 28, 213, 4, 6],\n",
              " [212, 28, 2, 15, 102, 68, 28, 213, 4, 6, 51],\n",
              " [212, 28, 2, 15, 102, 68, 28, 213, 4, 6, 51, 2],\n",
              " [212, 28, 2, 15, 102, 68, 28, 213, 4, 6, 51, 2, 1],\n",
              " [212, 28, 2, 15, 102, 68, 28, 213, 4, 6, 51, 2, 1, 11],\n",
              " [212, 28, 2, 15, 102, 68, 28, 213, 4, 6, 51, 2, 1, 11, 13],\n",
              " [69, 1],\n",
              " [69, 1, 214],\n",
              " [69, 1, 214, 2],\n",
              " [69, 1, 214, 2, 1],\n",
              " [69, 1, 214, 2, 1, 51],\n",
              " [69, 1, 214, 2, 1, 51, 33],\n",
              " [69, 1, 214, 2, 1, 51, 33, 92],\n",
              " [69, 1, 214, 2, 1, 51, 33, 92, 215],\n",
              " [69, 1, 214, 2, 1, 51, 33, 92, 215, 9],\n",
              " [69, 1, 214, 2, 1, 51, 33, 92, 215, 9, 1],\n",
              " [69, 1, 214, 2, 1, 51, 33, 92, 215, 9, 1, 29],\n",
              " [69, 1, 214, 2, 1, 51, 33, 92, 215, 9, 1, 29, 216],\n",
              " [69, 1, 214, 2, 1, 51, 33, 92, 215, 9, 1, 29, 216, 30],\n",
              " [69, 1, 214, 2, 1, 51, 33, 92, 215, 9, 1, 29, 216, 30, 103],\n",
              " [104, 15],\n",
              " [104, 15, 5],\n",
              " [104, 15, 5, 8],\n",
              " [104, 15, 5, 8, 217],\n",
              " [104, 15, 5, 8, 217, 15],\n",
              " [104, 15, 5, 8, 217, 15, 5],\n",
              " [104, 15, 5, 8, 217, 15, 5, 105],\n",
              " [104, 15, 5, 8, 217, 15, 5, 105, 7],\n",
              " [5, 218],\n",
              " [5, 218, 219],\n",
              " [5, 218, 219, 220],\n",
              " [5, 218, 219, 220, 26],\n",
              " [5, 218, 219, 220, 26, 221],\n",
              " [5, 218, 219, 220, 26, 221, 222],\n",
              " [5, 218, 219, 220, 26, 221, 222, 2],\n",
              " [5, 218, 219, 220, 26, 221, 222, 2, 99],\n",
              " [5, 218, 219, 220, 26, 221, 222, 2, 99, 28],\n",
              " [5, 218, 219, 220, 26, 221, 222, 2, 99, 28, 2],\n",
              " [5, 218, 219, 220, 26, 221, 222, 2, 99, 28, 2, 223],\n",
              " [8, 106],\n",
              " [8, 106, 39],\n",
              " [8, 106, 39, 107],\n",
              " [8, 106, 39, 107, 224],\n",
              " [8, 106, 39, 107, 224, 19],\n",
              " [8, 106, 39, 107, 224, 19, 83],\n",
              " [8, 106, 39, 107, 224, 19, 83, 4],\n",
              " [8, 106, 39, 107, 224, 19, 83, 4, 225],\n",
              " [8, 106, 39, 107, 224, 19, 83, 4, 225, 11],\n",
              " [8, 106, 39, 107, 224, 19, 83, 4, 225, 11, 226],\n",
              " [33, 227],\n",
              " [33, 227, 4],\n",
              " [33, 227, 4, 12],\n",
              " [33, 227, 4, 12, 5],\n",
              " [33, 227, 4, 12, 5, 108],\n",
              " [33, 227, 4, 12, 5, 108, 4],\n",
              " [33, 227, 4, 12, 5, 108, 4, 228],\n",
              " [33, 227, 4, 12, 5, 108, 4, 228, 20],\n",
              " [33, 227, 4, 12, 5, 108, 4, 228, 20, 5],\n",
              " [33, 227, 4, 12, 5, 108, 4, 228, 20, 5, 109],\n",
              " [33, 227, 4, 12, 5, 108, 4, 228, 20, 5, 109, 38],\n",
              " [33, 227, 4, 12, 5, 108, 4, 228, 20, 5, 109, 38, 26],\n",
              " [33, 227, 4, 12, 5, 108, 4, 228, 20, 5, 109, 38, 26, 90],\n",
              " [33, 227, 4, 12, 5, 108, 4, 228, 20, 5, 109, 38, 26, 90, 229],\n",
              " [230, 2],\n",
              " [230, 2, 15],\n",
              " [230, 2, 15, 2],\n",
              " [230, 2, 15, 2, 1],\n",
              " [230, 2, 15, 2, 1, 11],\n",
              " [230, 2, 15, 2, 1, 11, 231],\n",
              " [230, 2, 15, 2, 1, 11, 231, 106],\n",
              " [230, 2, 15, 2, 1, 11, 231, 106, 232],\n",
              " [230, 2, 15, 2, 1, 11, 231, 106, 232, 69],\n",
              " [230, 2, 15, 2, 1, 11, 231, 106, 232, 69, 233],\n",
              " [230, 2, 15, 2, 1, 11, 231, 106, 232, 69, 233, 5],\n",
              " [3, 7],\n",
              " [3, 7, 5],\n",
              " [3, 7, 5, 36],\n",
              " [3, 7, 5, 36, 104],\n",
              " [3, 7, 5, 36, 104, 15],\n",
              " [3, 7, 5, 36, 104, 15, 23],\n",
              " [3, 7, 5, 36, 104, 15, 23, 234],\n",
              " [3, 7, 5, 36, 104, 15, 23, 234, 235],\n",
              " [3, 7, 5, 36, 104, 15, 23, 234, 235, 107],\n",
              " [3, 7, 5, 36, 104, 15, 23, 234, 235, 107, 236],\n",
              " [27, 69],\n",
              " [27, 69, 110],\n",
              " [27, 69, 110, 237],\n",
              " [27, 69, 110, 237, 238],\n",
              " [27, 69, 110, 237, 238, 3],\n",
              " [27, 69, 110, 237, 238, 3, 239],\n",
              " [27, 69, 110, 237, 238, 3, 239, 28],\n",
              " [27, 69, 110, 237, 238, 3, 239, 28, 240],\n",
              " [27, 69, 110, 237, 238, 3, 239, 28, 240, 20],\n",
              " [27, 69, 110, 237, 238, 3, 239, 28, 240, 20, 241],\n",
              " [27, 69, 110, 237, 238, 3, 239, 28, 240, 20, 241, 2],\n",
              " [27, 69, 110, 237, 238, 3, 239, 28, 240, 20, 241, 2, 111],\n",
              " [27, 69, 110, 237, 238, 3, 239, 28, 240, 20, 241, 2, 111, 33],\n",
              " [1, 70],\n",
              " [1, 70, 110],\n",
              " [1, 70, 110, 242],\n",
              " [1, 70, 110, 242, 13],\n",
              " [1, 70, 110, 242, 13, 6],\n",
              " [1, 70, 110, 242, 13, 6, 64],\n",
              " [1, 70, 110, 242, 13, 6, 64, 4],\n",
              " [1, 70, 110, 242, 13, 6, 64, 4, 243],\n",
              " [1, 70, 110, 242, 13, 6, 64, 4, 243, 42],\n",
              " [1, 70, 110, 242, 13, 6, 64, 4, 243, 42, 43],\n",
              " [1, 70, 110, 242, 13, 6, 64, 4, 243, 42, 43, 57],\n",
              " [1, 70, 110, 242, 13, 6, 64, 4, 243, 42, 43, 57, 2],\n",
              " [1, 70, 110, 242, 13, 6, 64, 4, 243, 42, 43, 57, 2, 1],\n",
              " [1, 70, 110, 242, 13, 6, 64, 4, 243, 42, 43, 57, 2, 1, 244],\n",
              " [245, 246],\n",
              " [245, 246, 3],\n",
              " [245, 246, 3, 7],\n",
              " [245, 246, 3, 7, 5],\n",
              " [245, 246, 3, 7, 5, 71],\n",
              " [245, 246, 3, 7, 5, 71, 247],\n",
              " [245, 246, 3, 7, 5, 71, 247, 3],\n",
              " [245, 246, 3, 7, 5, 71, 247, 3, 248],\n",
              " [245, 246, 3, 7, 5, 71, 247, 3, 248, 41],\n",
              " [245, 246, 3, 7, 5, 71, 247, 3, 248, 41, 249],\n",
              " [245, 246, 3, 7, 5, 71, 247, 3, 248, 41, 249, 250],\n",
              " [245, 246, 3, 7, 5, 71, 247, 3, 248, 41, 249, 250, 19],\n",
              " [245, 246, 3, 7, 5, 71, 247, 3, 248, 41, 249, 250, 19, 72],\n",
              " [65, 2],\n",
              " [65, 2, 1],\n",
              " [65, 2, 1, 31],\n",
              " [65, 2, 1, 31, 7],\n",
              " [65, 2, 1, 31, 7, 5],\n",
              " [65, 2, 1, 31, 7, 5, 27],\n",
              " [65, 2, 1, 31, 7, 5, 27, 23],\n",
              " [65, 2, 1, 31, 7, 5, 27, 23, 251],\n",
              " [65, 2, 1, 31, 7, 5, 27, 23, 251, 27],\n",
              " [65, 2, 1, 31, 7, 5, 27, 23, 251, 27, 2],\n",
              " [65, 2, 1, 31, 7, 5, 27, 23, 251, 27, 2, 1],\n",
              " [65, 2, 1, 31, 7, 5, 27, 23, 251, 27, 2, 1, 31],\n",
              " [252, 112],\n",
              " [252, 112, 253],\n",
              " [252, 112, 253, 10],\n",
              " [252, 112, 253, 10, 1],\n",
              " [252, 112, 253, 10, 1, 31],\n",
              " [252, 112, 253, 10, 1, 31, 254],\n",
              " [252, 112, 253, 10, 1, 31, 254, 113],\n",
              " [252, 112, 253, 10, 1, 31, 254, 113, 44],\n",
              " [252, 112, 253, 10, 1, 31, 254, 113, 44, 1],\n",
              " [252, 112, 253, 10, 1, 31, 254, 113, 44, 1, 5],\n",
              " [252, 112, 253, 10, 1, 31, 254, 113, 44, 1, 5, 255],\n",
              " [256, 257],\n",
              " [256, 257, 3],\n",
              " [256, 257, 3, 105],\n",
              " [256, 257, 3, 105, 7],\n",
              " [256, 257, 3, 105, 7, 5],\n",
              " [256, 257, 3, 105, 7, 5, 27],\n",
              " [256, 257, 3, 105, 7, 5, 27, 45],\n",
              " [256, 257, 3, 105, 7, 5, 27, 45, 37],\n",
              " [256, 257, 3, 105, 7, 5, 27, 45, 37, 258],\n",
              " [256, 257, 3, 105, 7, 5, 27, 45, 37, 258, 114],\n",
              " [256, 257, 3, 105, 7, 5, 27, 45, 37, 258, 114, 259],\n",
              " [256, 257, 3, 105, 7, 5, 27, 45, 37, 258, 114, 259, 260],\n",
              " [256, 257, 3, 105, 7, 5, 27, 45, 37, 258, 114, 259, 260, 261],\n",
              " [262, 263],\n",
              " [262, 263, 10],\n",
              " [262, 263, 10, 7],\n",
              " [262, 263, 10, 7, 5],\n",
              " [262, 263, 10, 7, 5, 264],\n",
              " [262, 263, 10, 7, 5, 264, 44],\n",
              " [262, 263, 10, 7, 5, 264, 44, 1],\n",
              " [262, 263, 10, 7, 5, 264, 44, 1, 31],\n",
              " [262, 263, 10, 7, 5, 264, 44, 1, 31, 26],\n",
              " [262, 263, 10, 7, 5, 264, 44, 1, 31, 26, 73],\n",
              " [262, 263, 10, 7, 5, 264, 44, 1, 31, 26, 73, 265],\n",
              " [262, 263, 10, 7, 5, 264, 44, 1, 31, 26, 73, 265, 115],\n",
              " [262, 263, 10, 7, 5, 264, 44, 1, 31, 26, 73, 265, 115, 1],\n",
              " [31, 42],\n",
              " [31, 42, 10],\n",
              " [31, 42, 10, 100],\n",
              " [31, 42, 10, 100, 1],\n",
              " [31, 42, 10, 100, 1, 266],\n",
              " [31, 42, 10, 100, 1, 266, 16],\n",
              " [31, 42, 10, 100, 1, 266, 16, 267],\n",
              " [31, 42, 10, 100, 1, 266, 16, 267, 14],\n",
              " [31, 42, 10, 100, 1, 266, 16, 267, 14, 268],\n",
              " [31, 42, 10, 100, 1, 266, 16, 267, 14, 268, 8],\n",
              " [31, 42, 10, 100, 1, 266, 16, 267, 14, 268, 8, 269],\n",
              " [31, 42, 10, 100, 1, 266, 16, 267, 14, 268, 8, 269, 9],\n",
              " [31, 42, 10, 100, 1, 266, 16, 267, 14, 268, 8, 269, 9, 62],\n",
              " [270, 4],\n",
              " [270, 4, 1],\n",
              " [270, 4, 1, 29],\n",
              " [270, 4, 1, 29, 4],\n",
              " [270, 4, 1, 29, 4, 271],\n",
              " [270, 4, 1, 29, 4, 271, 2],\n",
              " [270, 4, 1, 29, 4, 271, 2, 7],\n",
              " [270, 4, 1, 29, 4, 271, 2, 7, 5],\n",
              " [270, 4, 1, 29, 4, 271, 2, 7, 5, 17],\n",
              " [270, 4, 1, 29, 4, 271, 2, 7, 5, 17, 116],\n",
              " [270, 4, 1, 29, 4, 271, 2, 7, 5, 17, 116, 3],\n",
              " [270, 4, 1, 29, 4, 271, 2, 7, 5, 17, 116, 3, 54],\n",
              " [270, 4, 1, 29, 4, 271, 2, 7, 5, 17, 116, 3, 54, 55],\n",
              " [270, 4, 1, 29, 4, 271, 2, 7, 5, 17, 116, 3, 54, 55, 272],\n",
              " [270, 4, 1, 29, 4, 271, 2, 7, 5, 17, 116, 3, 54, 55, 272, 4],\n",
              " [270, 4, 1, 29, 4, 271, 2, 7, 5, 17, 116, 3, 54, 55, 272, 4, 273],\n",
              " [274, 45],\n",
              " [274, 45, 117],\n",
              " [274, 45, 117, 275],\n",
              " [274, 45, 117, 275, 10],\n",
              " [274, 45, 117, 275, 10, 276],\n",
              " [274, 45, 117, 275, 10, 276, 2],\n",
              " [274, 45, 117, 275, 10, 276, 2, 277],\n",
              " [274, 45, 117, 275, 10, 276, 2, 277, 44],\n",
              " [274, 45, 117, 275, 10, 276, 2, 277, 44, 72],\n",
              " [274, 45, 117, 275, 10, 276, 2, 277, 44, 72, 278],\n",
              " [274, 45, 117, 275, 10, 276, 2, 277, 44, 72, 278, 279],\n",
              " [274, 45, 117, 275, 10, 276, 2, 277, 44, 72, 278, 279, 8],\n",
              " [274, 45, 117, 275, 10, 276, 2, 277, 44, 72, 278, 279, 8, 280],\n",
              " [274, 45, 117, 275, 10, 276, 2, 277, 44, 72, 278, 279, 8, 280, 8],\n",
              " [45, 37],\n",
              " [45, 37, 17],\n",
              " [45, 37, 17, 281],\n",
              " [45, 37, 17, 281, 282],\n",
              " [45, 37, 17, 281, 282, 113],\n",
              " [45, 37, 17, 281, 282, 113, 45],\n",
              " [45, 37, 17, 281, 282, 113, 45, 37],\n",
              " [45, 37, 17, 281, 282, 113, 45, 37, 30],\n",
              " [45, 37, 17, 281, 282, 113, 45, 37, 30, 283],\n",
              " [45, 37, 17, 281, 282, 113, 45, 37, 30, 283, 60],\n",
              " [45, 37, 17, 281, 282, 113, 45, 37, 30, 283, 60, 284],\n",
              " [45, 37, 17, 281, 282, 113, 45, 37, 30, 283, 60, 284, 285],\n",
              " [45, 37, 17, 281, 282, 113, 45, 37, 30, 283, 60, 284, 285, 286],\n",
              " [7, 5],\n",
              " [7, 5, 8],\n",
              " [7, 5, 8, 287],\n",
              " [7, 5, 8, 287, 9],\n",
              " [7, 5, 8, 287, 9, 72],\n",
              " [7, 5, 8, 287, 9, 72, 288],\n",
              " [7, 5, 8, 287, 9, 72, 288, 7],\n",
              " [7, 5, 8, 287, 9, 72, 288, 7, 5],\n",
              " [7, 5, 8, 287, 9, 72, 288, 7, 5, 13],\n",
              " [7, 5, 8, 287, 9, 72, 288, 7, 5, 13, 6],\n",
              " [7, 5, 8, 287, 9, 72, 288, 7, 5, 13, 6, 289],\n",
              " [7, 5, 8, 287, 9, 72, 288, 7, 5, 13, 6, 289, 290],\n",
              " [291, 9],\n",
              " [291, 9, 5],\n",
              " [291, 9, 5, 15],\n",
              " [291, 9, 5, 15, 19],\n",
              " [291, 9, 5, 15, 19, 11],\n",
              " [291, 9, 5, 15, 19, 11, 43],\n",
              " [291, 9, 5, 15, 19, 11, 43, 7],\n",
              " [291, 9, 5, 15, 19, 11, 43, 7, 5],\n",
              " [291, 9, 5, 15, 19, 11, 43, 7, 5, 13],\n",
              " [291, 9, 5, 15, 19, 11, 43, 7, 5, 13, 6],\n",
              " [291, 9, 5, 15, 19, 11, 43, 7, 5, 13, 6, 292],\n",
              " [291, 9, 5, 15, 19, 11, 43, 7, 5, 13, 6, 292, 293],\n",
              " [291, 9, 5, 15, 19, 11, 43, 7, 5, 13, 6, 292, 293, 97],\n",
              " [291, 9, 5, 15, 19, 11, 43, 7, 5, 13, 6, 292, 293, 97, 2],\n",
              " [291, 9, 5, 15, 19, 11, 43, 7, 5, 13, 6, 292, 293, 97, 2, 12],\n",
              " [291, 9, 5, 15, 19, 11, 43, 7, 5, 13, 6, 292, 293, 97, 2, 12, 5],\n",
              " [291, 9, 5, 15, 19, 11, 43, 7, 5, 13, 6, 292, 293, 97, 2, 12, 5, 16],\n",
              " [291, 9, 5, 15, 19, 11, 43, 7, 5, 13, 6, 292, 293, 97, 2, 12, 5, 16, 109],\n",
              " [291,\n",
              "  9,\n",
              "  5,\n",
              "  15,\n",
              "  19,\n",
              "  11,\n",
              "  43,\n",
              "  7,\n",
              "  5,\n",
              "  13,\n",
              "  6,\n",
              "  292,\n",
              "  293,\n",
              "  97,\n",
              "  2,\n",
              "  12,\n",
              "  5,\n",
              "  16,\n",
              "  109,\n",
              "  294],\n",
              " [291,\n",
              "  9,\n",
              "  5,\n",
              "  15,\n",
              "  19,\n",
              "  11,\n",
              "  43,\n",
              "  7,\n",
              "  5,\n",
              "  13,\n",
              "  6,\n",
              "  292,\n",
              "  293,\n",
              "  97,\n",
              "  2,\n",
              "  12,\n",
              "  5,\n",
              "  16,\n",
              "  109,\n",
              "  294,\n",
              "  4],\n",
              " [295, 3],\n",
              " [295, 3, 1],\n",
              " [295, 3, 1, 46],\n",
              " [295, 3, 1, 46, 296],\n",
              " [295, 3, 1, 46, 296, 3],\n",
              " [295, 3, 1, 46, 296, 3, 1],\n",
              " [295, 3, 1, 46, 296, 3, 1, 74],\n",
              " [295, 3, 1, 46, 296, 3, 1, 74, 32],\n",
              " [295, 3, 1, 46, 296, 3, 1, 74, 32, 297],\n",
              " [295, 3, 1, 46, 296, 3, 1, 74, 32, 297, 16],\n",
              " [295, 3, 1, 46, 296, 3, 1, 74, 32, 297, 16, 47],\n",
              " [295, 3, 1, 46, 296, 3, 1, 74, 32, 297, 16, 47, 66],\n",
              " [295, 3, 1, 46, 296, 3, 1, 74, 32, 297, 16, 47, 66, 298],\n",
              " [295, 3, 1, 46, 296, 3, 1, 74, 32, 297, 16, 47, 66, 298, 75],\n",
              " [295, 3, 1, 46, 296, 3, 1, 74, 32, 297, 16, 47, 66, 298, 75, 2],\n",
              " [6, 299],\n",
              " [6, 299, 3],\n",
              " [6, 299, 3, 1],\n",
              " [6, 299, 3, 1, 29],\n",
              " [6, 299, 3, 1, 29, 18],\n",
              " [6, 299, 3, 1, 29, 18, 118],\n",
              " [6, 299, 3, 1, 29, 18, 118, 300],\n",
              " [6, 299, 3, 1, 29, 18, 118, 300, 20],\n",
              " [6, 299, 3, 1, 29, 18, 118, 300, 20, 301],\n",
              " [6, 299, 3, 1, 29, 18, 118, 300, 20, 301, 302],\n",
              " [6, 299, 3, 1, 29, 18, 118, 300, 20, 301, 302, 40],\n",
              " [6, 299, 3, 1, 29, 18, 118, 300, 20, 301, 302, 40, 17],\n",
              " [6, 299, 3, 1, 29, 18, 118, 300, 20, 301, 302, 40, 17, 303],\n",
              " [304, 8],\n",
              " [304, 8, 305],\n",
              " [304, 8, 305, 306],\n",
              " [304, 8, 305, 306, 307],\n",
              " [304, 8, 305, 306, 307, 10],\n",
              " [304, 8, 305, 306, 307, 10, 308],\n",
              " [304, 8, 305, 306, 307, 10, 308, 119],\n",
              " [304, 8, 305, 306, 307, 10, 308, 119, 8],\n",
              " [304, 8, 305, 306, 307, 10, 308, 119, 8, 309],\n",
              " [304, 8, 305, 306, 307, 10, 308, 119, 8, 309, 4],\n",
              " [304, 8, 305, 306, 307, 10, 308, 119, 8, 309, 4, 310],\n",
              " [42, 30],\n",
              " [42, 30, 48],\n",
              " [42, 30, 48, 103],\n",
              " [42, 30, 48, 103, 120],\n",
              " [42, 30, 48, 103, 120, 9],\n",
              " [42, 30, 48, 103, 120, 9, 311],\n",
              " [3, 312],\n",
              " [3, 312, 7],\n",
              " [3, 312, 7, 5],\n",
              " [3, 312, 7, 5, 47],\n",
              " [3, 312, 7, 5, 47, 66],\n",
              " [3, 312, 7, 5, 47, 66, 1],\n",
              " [3, 312, 7, 5, 47, 66, 1, 313],\n",
              " [3, 312, 7, 5, 47, 66, 1, 313, 314],\n",
              " [3, 312, 7, 5, 47, 66, 1, 313, 314, 39],\n",
              " [3, 312, 7, 5, 47, 66, 1, 313, 314, 39, 3],\n",
              " [3, 312, 7, 5, 47, 66, 1, 313, 314, 39, 3, 315],\n",
              " [316, 58],\n",
              " [316, 58, 317],\n",
              " [316, 58, 317, 2],\n",
              " [316, 58, 317, 2, 12],\n",
              " [316, 58, 317, 2, 12, 5],\n",
              " [49, 76],\n",
              " [49, 76, 21],\n",
              " [49, 76, 21, 24],\n",
              " [49, 76, 21, 24, 56],\n",
              " [49, 76, 21, 24, 56, 96],\n",
              " [49, 76],\n",
              " [49, 76, 21],\n",
              " [49, 76, 21, 24],\n",
              " [49, 76, 21, 24, 318],\n",
              " [49, 76, 21, 24, 318, 319],\n",
              " [49, 76],\n",
              " [49, 76, 21],\n",
              " [49, 76, 21, 24],\n",
              " [49, 76, 21, 24, 320],\n",
              " [49, 76, 21, 24, 320, 321],\n",
              " [49, 322],\n",
              " [49, 322, 12],\n",
              " [49, 322, 12, 323],\n",
              " [49, 322, 12, 323, 117],\n",
              " [49, 322, 12, 323, 117, 324],\n",
              " [49, 322, 12, 323, 117, 324, 1],\n",
              " [49, 322, 12, 323, 117, 324, 1, 75],\n",
              " [49, 322, 12, 323, 117, 324, 1, 75, 70],\n",
              " [49, 322, 12, 323, 117, 324, 1, 75, 70, 325],\n",
              " [43, 7],\n",
              " [43, 7, 5],\n",
              " [43, 7, 5, 47],\n",
              " [43, 7, 5, 47, 326],\n",
              " [43, 7, 5, 47, 326, 4],\n",
              " [43, 7, 5, 47, 326, 4, 118],\n",
              " [43, 7, 5, 47, 326, 4, 118, 327],\n",
              " [43, 7, 5, 47, 326, 4, 118, 327, 3],\n",
              " [43, 7, 5, 47, 326, 4, 118, 327, 3, 328],\n",
              " [43, 7, 5, 47, 326, 4, 118, 327, 3, 328, 32],\n",
              " [43, 7, 5, 47, 326, 4, 118, 327, 3, 328, 32, 329],\n",
              " [330, 9],\n",
              " [330, 9, 121],\n",
              " [330, 9, 121, 1],\n",
              " [330, 9, 121, 1, 29],\n",
              " [330, 9, 121, 1, 29, 25],\n",
              " [330, 9, 121, 1, 29, 25, 14],\n",
              " [330, 9, 121, 1, 29, 25, 14, 331],\n",
              " [330, 9, 121, 1, 29, 25, 14, 331, 4],\n",
              " [330, 9, 121, 1, 29, 25, 14, 331, 4, 332],\n",
              " [330, 9, 121, 1, 29, 25, 14, 331, 4, 332, 3],\n",
              " [330, 9, 121, 1, 29, 25, 14, 331, 4, 332, 3, 1],\n",
              " [330, 9, 121, 1, 29, 25, 14, 331, 4, 332, 3, 1, 333],\n",
              " [330, 9, 121, 1, 29, 25, 14, 331, 4, 332, 3, 1, 333, 334],\n",
              " [330, 9, 121, 1, 29, 25, 14, 331, 4, 332, 3, 1, 333, 334, 108],\n",
              " [330, 9, 121, 1, 29, 25, 14, 331, 4, 332, 3, 1, 333, 334, 108, 4],\n",
              " [330, 9, 121, 1, 29, 25, 14, 331, 4, 332, 3, 1, 333, 334, 108, 4, 335],\n",
              " [330, 9, 121, 1, 29, 25, 14, 331, 4, 332, 3, 1, 333, 334, 108, 4, 335, 336],\n",
              " [337, 338],\n",
              " [337, 338, 121],\n",
              " [337, 338, 121, 25],\n",
              " [337, 338, 121, 25, 122],\n",
              " [337, 338, 121, 25, 122, 14],\n",
              " [337, 338, 121, 25, 122, 14, 339],\n",
              " [337, 338, 121, 25, 122, 14, 339, 43],\n",
              " [337, 338, 121, 25, 122, 14, 339, 43, 57],\n",
              " [337, 338, 121, 25, 122, 14, 339, 43, 57, 123],\n",
              " [337, 338, 121, 25, 122, 14, 339, 43, 57, 123, 340],\n",
              " [337, 338, 121, 25, 122, 14, 339, 43, 57, 123, 340, 341],\n",
              " [44, 342],\n",
              " [44, 342, 343],\n",
              " [44, 342, 343, 23],\n",
              " [44, 342, 343, 23, 344],\n",
              " [44, 342, 343, 23, 344, 345],\n",
              " [44, 342, 343, 23, 344, 345, 346],\n",
              " [44, 342, 343, 23, 344, 345, 346, 68],\n",
              " [44, 342, 343, 23, 344, 345, 346, 68, 61],\n",
              " [44, 342, 343, 23, 344, 345, 346, 68, 61, 23],\n",
              " [44, 342, 343, 23, 344, 345, 346, 68, 61, 23, 122],\n",
              " [44, 342, 343, 23, 344, 345, 346, 68, 61, 23, 122, 4],\n",
              " [44, 342, 343, 23, 344, 345, 346, 68, 61, 23, 122, 4, 347],\n",
              " [44, 342, 343, 23, 344, 345, 346, 68, 61, 23, 122, 4, 347, 120],\n",
              " [9, 6],\n",
              " [9, 6, 48],\n",
              " [9, 6, 48, 124],\n",
              " [9, 6, 48, 124, 40],\n",
              " [9, 6, 48, 124, 40, 17],\n",
              " [9, 6, 48, 124, 40, 17, 348],\n",
              " [9, 6, 48, 124, 40, 17, 348, 349],\n",
              " [9, 6, 48, 124, 40, 17, 348, 349, 50],\n",
              " [9, 6, 48, 124, 40, 17, 348, 349, 50, 21],\n",
              " [9, 6, 48, 124, 40, 17, 348, 349, 50, 21, 24],\n",
              " [9, 6, 48, 124, 40, 17, 348, 349, 50, 21, 24, 12],\n",
              " [9, 6, 48, 124, 40, 17, 348, 349, 50, 21, 24, 12, 350],\n",
              " [114, 351],\n",
              " [114, 351, 352],\n",
              " [114, 351, 352, 8],\n",
              " [114, 351, 352, 8, 21],\n",
              " [114, 351, 352, 8, 21, 24],\n",
              " [114, 351, 352, 8, 21, 24, 119],\n",
              " [114, 351, 352, 8, 21, 24, 119, 353],\n",
              " [114, 351, 352, 8, 21, 24, 119, 353, 65],\n",
              " [114, 351, 352, 8, 21, 24, 119, 353, 65, 3],\n",
              " [114, 351, 352, 8, 21, 24, 119, 353, 65, 3, 354],\n",
              " [355, 356],\n",
              " [355, 356, 2],\n",
              " [355, 356, 2, 21],\n",
              " [355, 356, 2, 21, 24],\n",
              " [355, 356, 2, 21, 24, 125],\n",
              " [355, 356, 2, 21, 24, 125, 126],\n",
              " [355, 356, 2, 21, 24, 125, 126, 357],\n",
              " [355, 356, 2, 21, 24, 125, 126, 357, 14],\n",
              " [355, 356, 2, 21, 24, 125, 126, 357, 14, 358],\n",
              " [355, 356, 2, 21, 24, 125, 126, 357, 14, 358, 359],\n",
              " [355, 356, 2, 21, 24, 125, 126, 357, 14, 358, 359, 360],\n",
              " [355, 356, 2, 21, 24, 125, 126, 357, 14, 358, 359, 360, 1],\n",
              " [355, 356, 2, 21, 24, 125, 126, 357, 14, 358, 359, 360, 1, 361],\n",
              " [18, 77],\n",
              " [18, 77, 127],\n",
              " [18, 77, 127, 9],\n",
              " [18, 77, 127, 9, 1],\n",
              " [18, 77, 127, 9, 1, 75],\n",
              " [18, 77, 127, 9, 1, 75, 70],\n",
              " [18, 77, 127, 9, 1, 75, 70, 13],\n",
              " [18, 77, 127, 9, 1, 75, 70, 13, 10],\n",
              " [18, 77, 127, 9, 1, 75, 70, 13, 10, 17],\n",
              " [18, 77, 127, 9, 1, 75, 70, 13, 10, 17, 128],\n",
              " [18, 77, 127, 9, 1, 75, 70, 13, 10, 17, 128, 362],\n",
              " [18, 77, 127, 9, 1, 75, 70, 13, 10, 17, 128, 362, 4],\n",
              " [18, 77, 127, 9, 1, 75, 70, 13, 10, 17, 128, 362, 4, 363],\n",
              " [364, 129],\n",
              " [364, 129, 25],\n",
              " [364, 129, 25, 365],\n",
              " [364, 129, 25, 365, 366],\n",
              " [364, 129, 25, 365, 366, 367],\n",
              " [364, 129, 25, 365, 366, 367, 368],\n",
              " [364, 129, 25, 365, 366, 367, 368, 9],\n",
              " [364, 129, 25, 365, 366, 367, 368, 9, 6],\n",
              " [364, 129, 25, 365, 366, 367, 368, 9, 6, 48],\n",
              " [364, 129, 25, 365, 366, 367, 368, 9, 6, 48, 124],\n",
              " [67, 47],\n",
              " [67, 47, 369],\n",
              " [67, 47, 369, 85],\n",
              " [67, 47, 369, 85, 370],\n",
              " [67, 47, 369, 85, 370, 3],\n",
              " [67, 47, 369, 85, 370, 3, 1],\n",
              " [67, 47, 369, 85, 370, 3, 1, 371],\n",
              " [67, 47, 369, 85, 370, 3, 1, 371, 22],\n",
              " [67, 47, 369, 85, 370, 3, 1, 371, 22, 372],\n",
              " [67, 47, 369, 85, 370, 3, 1, 371, 22, 372, 373],\n",
              " [67, 47, 369, 85, 370, 3, 1, 371, 22, 372, 373, 6],\n",
              " [67, 47, 369, 85, 370, 3, 1, 371, 22, 372, 373, 6, 374],\n",
              " [67, 47, 369, 85, 370, 3, 1, 371, 22, 372, 373, 6, 374, 2],\n",
              " [67, 47, 369, 85, 370, 3, 1, 371, 22, 372, 373, 6, 374, 2, 375],\n",
              " [376, 377],\n",
              " [376, 377, 41],\n",
              " [376, 377, 41, 378],\n",
              " [376, 377, 41, 378, 8],\n",
              " [376, 377, 41, 378, 8, 379],\n",
              " [376, 377, 41, 378, 8, 379, 18],\n",
              " [376, 377, 41, 378, 8, 379, 18, 6],\n",
              " [376, 377, 41, 378, 8, 379, 18, 6, 380],\n",
              " [376, 377, 41, 378, 8, 379, 18, 6, 380, 2],\n",
              " [376, 377, 41, 378, 8, 379, 18, 6, 380, 2, 381],\n",
              " [376, 377, 41, 378, 8, 379, 18, 6, 380, 2, 381, 17],\n",
              " [376, 377, 41, 378, 8, 379, 18, 6, 380, 2, 381, 17, 6],\n",
              " [382, 16],\n",
              " [382, 16, 130],\n",
              " [382, 16, 130, 18],\n",
              " [382, 16, 130, 18, 78],\n",
              " [382, 16, 130, 18, 78, 22],\n",
              " [382, 16, 130, 18, 78, 22, 3],\n",
              " [382, 16, 130, 18, 78, 22, 3, 1],\n",
              " [382, 16, 130, 18, 78, 22, 3, 1, 131],\n",
              " [382, 16, 130, 18, 78, 22, 3, 1, 131, 3],\n",
              " [382, 16, 130, 18, 78, 22, 3, 1, 131, 3, 383],\n",
              " [382, 16, 130, 18, 78, 22, 3, 1, 131, 3, 383, 46],\n",
              " [382, 16, 130, 18, 78, 22, 3, 1, 131, 3, 383, 46, 384],\n",
              " [382, 16, 130, 18, 78, 22, 3, 1, 131, 3, 383, 46, 384, 385],\n",
              " [382, 16, 130, 18, 78, 22, 3, 1, 131, 3, 383, 46, 384, 385, 60],\n",
              " [382, 16, 130, 18, 78, 22, 3, 1, 131, 3, 383, 46, 384, 385, 60, 22],\n",
              " [71, 386],\n",
              " [71, 386, 77],\n",
              " [71, 386, 77, 38],\n",
              " [71, 386, 77, 38, 2],\n",
              " [71, 386, 77, 38, 2, 1],\n",
              " [71, 386, 77, 38, 2, 1, 387],\n",
              " [71, 386, 77, 38, 2, 1, 387, 84],\n",
              " [71, 386, 77, 38, 2, 1, 387, 84, 388],\n",
              " [71, 386, 77, 38, 2, 1, 387, 84, 388, 8],\n",
              " [71, 386, 77, 38, 2, 1, 387, 84, 388, 8, 389],\n",
              " [71, 386, 77, 38, 2, 1, 387, 84, 388, 8, 389, 2],\n",
              " [71, 386, 77, 38, 2, 1, 387, 84, 388, 8, 389, 2, 1],\n",
              " [71, 386, 77, 38, 2, 1, 387, 84, 388, 8, 389, 2, 1, 78],\n",
              " [71, 386, 77, 38, 2, 1, 387, 84, 388, 8, 389, 2, 1, 78, 22],\n",
              " [101, 73],\n",
              " [101, 73, 390],\n",
              " [101, 73, 390, 391],\n",
              " [101, 73, 390, 391, 392],\n",
              " [101, 73, 390, 391, 392, 393],\n",
              " [101, 73, 390, 391, 392, 393, 3],\n",
              " [101, 73, 390, 391, 392, 393, 3, 394],\n",
              " [101, 73, 390, 391, 392, 393, 3, 394, 395],\n",
              " [101, 73, 390, 391, 392, 393, 3, 394, 395, 6],\n",
              " [101, 73, 390, 391, 392, 393, 3, 394, 395, 6, 396],\n",
              " [101, 73, 390, 391, 392, 393, 3, 394, 395, 6, 396, 397],\n",
              " [101, 73, 390, 391, 392, 393, 3, 394, 395, 6, 396, 397, 1],\n",
              " [101, 73, 390, 391, 392, 393, 3, 394, 395, 6, 396, 397, 1, 398],\n",
              " [399, 2],\n",
              " [399, 2, 400],\n",
              " [399, 2, 400, 401],\n",
              " [399, 2, 400, 401, 402],\n",
              " [399, 2, 400, 401, 402, 25],\n",
              " [399, 2, 400, 401, 402, 25, 403],\n",
              " [399, 2, 400, 401, 402, 25, 403, 14],\n",
              " [399, 2, 400, 401, 402, 25, 403, 14, 404],\n",
              " [399, 2, 400, 401, 402, 25, 403, 14, 404, 132],\n",
              " [399, 2, 400, 401, 402, 25, 403, 14, 404, 132, 133],\n",
              " [399, 2, 400, 401, 402, 25, 403, 14, 404, 132, 133, 32],\n",
              " [399, 2, 400, 401, 402, 25, 403, 14, 404, 132, 133, 32, 134],\n",
              " [399, 2, 400, 401, 402, 25, 403, 14, 404, 132, 133, 32, 134, 3],\n",
              " [405, 406],\n",
              " [405, 406, 407],\n",
              " [405, 406, 407, 6],\n",
              " [405, 406, 407, 6, 61],\n",
              " [405, 406, 407, 6, 61, 408],\n",
              " [405, 406, 407, 6, 61, 408, 409],\n",
              " [405, 406, 407, 6, 61, 408, 409, 410],\n",
              " [405, 406, 407, 6, 61, 408, 409, 410, 411],\n",
              " [405, 406, 407, 6, 61, 408, 409, 410, 411, 19],\n",
              " [405, 406, 407, 6, 61, 408, 409, 410, 411, 19, 133],\n",
              " [405, 406, 407, 6, 61, 408, 409, 410, 411, 19, 133, 4],\n",
              " [405, 406, 407, 6, 61, 408, 409, 410, 411, 19, 133, 4, 412],\n",
              " [405, 406, 407, 6, 61, 408, 409, 410, 411, 19, 133, 4, 412, 32],\n",
              " [405, 406, 407, 6, 61, 408, 409, 410, 411, 19, 133, 4, 412, 32, 53],\n",
              " [25, 30],\n",
              " [25, 30, 6],\n",
              " [25, 30, 6, 12],\n",
              " [25, 30, 6, 12, 18],\n",
              " [25, 30, 6, 12, 18, 1],\n",
              " [25, 30, 6, 12, 18, 1, 125],\n",
              " [25, 30, 6, 12, 18, 1, 125, 126],\n",
              " [25, 30, 6, 12, 18, 1, 125, 126, 2],\n",
              " [25, 30, 6, 12, 18, 1, 125, 126, 2, 63],\n",
              " [25, 30, 6, 12, 18, 1, 125, 126, 2, 63, 413],\n",
              " [25, 30, 6, 12, 18, 1, 125, 126, 2, 63, 413, 21],\n",
              " [25, 30, 6, 12, 18, 1, 125, 126, 2, 63, 413, 21, 116],\n",
              " [25, 30, 6, 12, 18, 1, 125, 126, 2, 63, 413, 21, 116, 132],\n",
              " [25, 30, 6, 12, 18, 1, 125, 126, 2, 63, 413, 21, 116, 132, 3],\n",
              " [25, 30, 6, 12, 18, 1, 125, 126, 2, 63, 413, 21, 116, 132, 3, 414],\n",
              " [40, 63],\n",
              " [40, 63, 415],\n",
              " [40, 63, 415, 416],\n",
              " [40, 63, 415, 416, 417],\n",
              " [40, 63, 415, 416, 417, 4],\n",
              " [40, 63, 415, 416, 417, 4, 14],\n",
              " [40, 63, 415, 416, 417, 4, 14, 135],\n",
              " [40, 63, 415, 416, 417, 4, 14, 135, 3],\n",
              " [40, 63, 415, 416, 417, 4, 14, 135, 3, 1],\n",
              " [40, 63, 415, 416, 417, 4, 14, 135, 3, 1, 418],\n",
              " [40, 63, 415, 416, 417, 4, 14, 135, 3, 1, 418, 135],\n",
              " [40, 63, 415, 416, 417, 4, 14, 135, 3, 1, 418, 135, 10],\n",
              " [40, 63, 415, 416, 417, 4, 14, 135, 3, 1, 418, 135, 10, 53],\n",
              " [40, 63, 415, 416, 417, 4, 14, 135, 3, 1, 418, 135, 10, 53, 30],\n",
              " [40, 63, 415, 416, 417, 4, 14, 135, 3, 1, 418, 135, 10, 53, 30, 112],\n",
              " [40, 63, 415, 416, 417, 4, 14, 135, 3, 1, 418, 135, 10, 53, 30, 112, 55],\n",
              " [40, 63, 415, 416, 417, 4, 14, 135, 3, 1, 418, 135, 10, 53, 30, 112, 55, 4],\n",
              " [419, 102],\n",
              " [419, 102, 48],\n",
              " [419, 102, 48, 16],\n",
              " [419, 102, 48, 16, 25],\n",
              " [419, 102, 48, 16, 25, 420],\n",
              " [419, 102, 48, 16, 25, 420, 3],\n",
              " [419, 102, 48, 16, 25, 420, 3, 1],\n",
              " [419, 102, 48, 16, 25, 420, 3, 1, 131],\n",
              " [419, 102, 48, 16, 25, 420, 3, 1, 131, 8],\n",
              " [419, 102, 48, 16, 25, 420, 3, 1, 131, 8, 46],\n",
              " [419, 102, 48, 16, 25, 420, 3, 1, 131, 8, 46, 421],\n",
              " [419, 102, 48, 16, 25, 420, 3, 1, 131, 8, 46, 421, 422],\n",
              " [419, 102, 48, 16, 25, 420, 3, 1, 131, 8, 46, 421, 422, 423],\n",
              " [419, 102, 48, 16, 25, 420, 3, 1, 131, 8, 46, 421, 422, 423, 424],\n",
              " [16, 4],\n",
              " [16, 4, 14],\n",
              " [16, 4, 14, 425],\n",
              " [16, 4, 14, 425, 79],\n",
              " [16, 4, 14, 425, 79, 1],\n",
              " [16, 4, 14, 425, 79, 1, 426],\n",
              " [16, 4, 14, 425, 79, 1, 426, 17],\n",
              " [16, 4, 14, 425, 79, 1, 426, 17, 427],\n",
              " [16, 4, 14, 425, 79, 1, 426, 17, 427, 68],\n",
              " [16, 4, 14, 425, 79, 1, 426, 17, 427, 68, 428],\n",
              " [16, 4, 14, 425, 79, 1, 426, 17, 427, 68, 428, 429],\n",
              " [16, 4, 14, 425, 79, 1, 426, 17, 427, 68, 428, 429, 6],\n",
              " [16, 4, 14, 425, 79, 1, 426, 17, 427, 68, 428, 429, 6, 74],\n",
              " [16, 4, 14, 425, 79, 1, 426, 17, 427, 68, 428, 429, 6, 74, 32],\n",
              " [16, 4, 14, 425, 79, 1, 426, 17, 427, 68, 428, 429, 6, 74, 32, 134],\n",
              " [16, 4, 14, 425, 79, 1, 426, 17, 427, 68, 428, 429, 6, 74, 32, 134, 17],\n",
              " [16, 4, 14, 425, 79, 1, 426, 17, 427, 68, 428, 429, 6, 74, 32, 134, 17, 36],\n",
              " [77, 127],\n",
              " [77, 127, 430],\n",
              " [77, 127, 430, 4],\n",
              " [77, 127, 430, 4, 431],\n",
              " [77, 127, 430, 4, 431, 432],\n",
              " [77, 127, 430, 4, 431, 432, 8],\n",
              " [77, 127, 430, 4, 431, 432, 8, 433],\n",
              " [77, 127, 430, 4, 431, 432, 8, 433, 434],\n",
              " [77, 127, 430, 4, 431, 432, 8, 433, 434, 435],\n",
              " [436, 19],\n",
              " [436, 19, 1],\n",
              " [436, 19, 1, 29],\n",
              " [436, 19, 1, 29, 437],\n",
              " [436, 19, 1, 29, 437, 1],\n",
              " [436, 19, 1, 29, 437, 1, 438],\n",
              " [436, 19, 1, 29, 437, 1, 438, 2],\n",
              " [436, 19, 1, 29, 437, 1, 438, 2, 1],\n",
              " [436, 19, 1, 29, 437, 1, 438, 2, 1, 439],\n",
              " [436, 19, 1, 29, 437, 1, 438, 2, 1, 439, 22],\n",
              " [436, 19, 1, 29, 437, 1, 438, 2, 1, 439, 22, 440],\n",
              " [436, 19, 1, 29, 437, 1, 438, 2, 1, 439, 22, 440, 6],\n",
              " [436, 19, 1, 29, 437, 1, 438, 2, 1, 439, 22, 440, 6, 64],\n",
              " [436, 19, 1, 29, 437, 1, 438, 2, 1, 439, 22, 440, 6, 64, 4],\n",
              " [436, 19, 1, 29, 437, 1, 438, 2, 1, 439, 22, 440, 6, 64, 4, 6],\n",
              " [436, 19, 1, 29, 437, 1, 438, 2, 1, 439, 22, 440, 6, 64, 4, 6, 441],\n",
              " [436, 19, 1, 29, 437, 1, 438, 2, 1, 439, 22, 440, 6, 64, 4, 6, 441, 442],\n",
              " [443, 444],\n",
              " [443, 444, 67],\n",
              " [443, 444, 67, 73],\n",
              " [443, 444, 67, 73, 445],\n",
              " [443, 444, 67, 73, 445, 115],\n",
              " [443, 444, 67, 73, 445, 115, 1],\n",
              " [443, 444, 67, 73, 445, 115, 1, 446],\n",
              " [443, 444, 67, 73, 445, 115, 1, 446, 2],\n",
              " [443, 444, 67, 73, 445, 115, 1, 446, 2, 1],\n",
              " [443, 444, 67, 73, 445, 115, 1, 446, 2, 1, 447],\n",
              " [443, 444, 67, 73, 445, 115, 1, 446, 2, 1, 447, 448],\n",
              " [16, 449],\n",
              " [16, 449, 14],\n",
              " [16, 449, 14, 1],\n",
              " [16, 449, 14, 1, 450],\n",
              " [16, 449, 14, 1, 450, 38],\n",
              " [16, 449, 14, 1, 450, 38, 3],\n",
              " [16, 449, 14, 1, 450, 38, 3, 1],\n",
              " [16, 449, 14, 1, 450, 38, 3, 1, 451],\n",
              " [16, 449, 14, 1, 450, 38, 3, 1, 451, 6],\n",
              " [16, 449, 14, 1, 450, 38, 3, 1, 451, 6, 62],\n",
              " [16, 449, 14, 1, 450, 38, 3, 1, 451, 6, 62, 98],\n",
              " [16, 449, 14, 1, 450, 38, 3, 1, 451, 6, 62, 98, 20],\n",
              " [16, 449, 14, 1, 450, 38, 3, 1, 451, 6, 62, 98, 20, 78],\n",
              " [16, 449, 14, 1, 450, 38, 3, 1, 451, 6, 62, 98, 20, 78, 22],\n",
              " [16, 449, 14, 1, 450, 38, 3, 1, 451, 6, 62, 98, 20, 78, 22, 136],\n",
              " [16, 449, 14, 1, 450, 38, 3, 1, 451, 6, 62, 98, 20, 78, 22, 136, 50],\n",
              " [130, 452],\n",
              " [130, 452, 453],\n",
              " [130, 452, 453, 454],\n",
              " [130, 452, 453, 454, 455],\n",
              " [130, 452, 453, 454, 455, 137],\n",
              " [130, 452, 453, 454, 455, 137, 6],\n",
              " [130, 452, 453, 454, 455, 137, 6, 74],\n",
              " [130, 452, 453, 454, 455, 137, 6, 74, 456],\n",
              " [130, 452, 453, 454, 455, 137, 6, 74, 456, 457],\n",
              " [130, 452, 453, 454, 455, 137, 6, 74, 456, 457, 458],\n",
              " [130, 452, 453, 454, 455, 137, 6, 74, 456, 457, 458, 459],\n",
              " [6, 460],\n",
              " [6, 460, 2],\n",
              " [6, 460, 2, 129],\n",
              " [6, 460, 2, 129, 18],\n",
              " [6, 460, 2, 129, 18, 461],\n",
              " [6, 460, 2, 129, 18, 461, 79],\n",
              " [6, 460, 2, 129, 18, 461, 79, 1],\n",
              " [6, 460, 2, 129, 18, 461, 79, 1, 123],\n",
              " [6, 460, 2, 129, 18, 461, 79, 1, 123, 462],\n",
              " [6, 460, 2, 129, 18, 461, 79, 1, 123, 462, 95],\n",
              " [6, 460, 2, 129, 18, 461, 79, 1, 123, 462, 95, 463],\n",
              " [6, 460, 2, 129, 18, 461, 79, 1, 123, 462, 95, 463, 3],\n",
              " [6, 460, 2, 129, 18, 461, 79, 1, 123, 462, 95, 463, 3, 464],\n",
              " [22, 465],\n",
              " [22, 465, 4],\n",
              " [22, 465, 4, 466],\n",
              " [22, 465, 4, 466, 136],\n",
              " [22, 465, 4, 466, 136, 50],\n",
              " [22, 465, 4, 466, 136, 50, 79],\n",
              " [22, 465, 4, 466, 136, 50, 79, 467],\n",
              " [22, 465, 4, 466, 136, 50, 79, 467, 137],\n",
              " [22, 465, 4, 466, 136, 50, 79, 467, 137, 71],\n",
              " [22, 465, 4, 466, 136, 50, 79, 467, 137, 71, 468],\n",
              " [469, 470],\n",
              " [469, 470, 471],\n",
              " [469, 470, 471, 111],\n",
              " [469, 470, 471, 111, 472],\n",
              " [469, 470, 471, 111, 472, 20],\n",
              " [469, 470, 471, 111, 472, 20, 1],\n",
              " [469, 470, 471, 111, 472, 20, 1, 128],\n",
              " [469, 470, 471, 111, 472, 20, 1, 128, 42],\n",
              " [469, 470, 471, 111, 472, 20, 1, 128, 42, 41],\n",
              " [469, 470, 471, 111, 472, 20, 1, 128, 42, 41, 1],\n",
              " [469, 470, 471, 111, 472, 20, 1, 128, 42, 41, 1, 46],\n",
              " [469, 470, 471, 111, 472, 20, 1, 128, 42, 41, 1, 46, 473],\n",
              " [469, 470, 471, 111, 472, 20, 1, 128, 42, 41, 1, 46, 473, 36],\n",
              " [469, 470, 471, 111, 472, 20, 1, 128, 42, 41, 1, 46, 473, 36, 50],\n",
              " [469, 470, 471, 111, 472, 20, 1, 128, 42, 41, 1, 46, 473, 36, 50, 474],\n",
              " [475, 476],\n",
              " [475, 476, 4],\n",
              " [475, 476, 4, 477],\n",
              " [475, 476, 4, 477, 58],\n",
              " [475, 476, 4, 477, 58, 4],\n",
              " [475, 476, 4, 477, 58, 4, 478]]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length=max([len(x) for x in input_sequences])"
      ],
      "metadata": {
        "id": "dwACeIus8xBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "padded_input_sequences=pad_sequences(input_sequences,maxlen=max_length,padding='pre')"
      ],
      "metadata": {
        "id": "RpzD0qec88tU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=padded_input_sequences[:,:-1]\n",
        "y=padded_input_sequences[:,-1]"
      ],
      "metadata": {
        "id": "2dMgnk1a9WQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRkXl1pO9jy2",
        "outputId": "24e53992-f80f-44d7-be8f-580b6f707944"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(965, 25)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSYPB-9v-gfo",
        "outputId": "9d52a366-e4f5-4a2e-8c60-a6b32c2a2b1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(965,)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y=to_categorical(y,num_classes=len(tokenizer.word_index)+1)"
      ],
      "metadata": {
        "id": "xG4zk886-j7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKvsF6I1_HXY",
        "outputId": "e422c734-1de5-4c33-bee4-8f4c0a13cd6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(965, 479)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding,LSTM,Dense"
      ],
      "metadata": {
        "id": "j_jgXZ_A_8o4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Embedding(479,100,input_length=max_length-1))\n",
        "model.add(LSTM(200))\n",
        "model.add(Dense(479,activation='softmax'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_owKJsLAACr",
        "outputId": "bd6f6328-21eb-419e-c6f8-9e78bdc7cd11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "rM7fanAIAhMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "H5YA4AV6A8l3",
        "outputId": "38f73f4c-7c2e-4984-b8ea-ddea8af61ba7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x,y,epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWhcll6GEPyu",
        "outputId": "797f5214-bb4d-4bbd-e9c5-0e03e2cce219"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 52ms/step - accuracy: 0.0359 - loss: 6.0718\n",
            "Epoch 2/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.0469 - loss: 5.5552\n",
            "Epoch 3/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 0.0584 - loss: 5.4496\n",
            "Epoch 4/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.0491 - loss: 5.4618\n",
            "Epoch 5/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.0648 - loss: 5.4245\n",
            "Epoch 6/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.0685 - loss: 5.3858\n",
            "Epoch 7/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.0794 - loss: 5.2190\n",
            "Epoch 8/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.0933 - loss: 5.0596\n",
            "Epoch 9/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.0979 - loss: 4.8969\n",
            "Epoch 10/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.1304 - loss: 4.7034\n",
            "Epoch 11/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.1856 - loss: 4.4034\n",
            "Epoch 12/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.1853 - loss: 4.2397\n",
            "Epoch 13/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.2033 - loss: 4.0379\n",
            "Epoch 14/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.2279 - loss: 3.8061\n",
            "Epoch 15/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.2471 - loss: 3.6210\n",
            "Epoch 16/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.2955 - loss: 3.3629\n",
            "Epoch 17/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.3252 - loss: 3.0860\n",
            "Epoch 18/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.3417 - loss: 2.9712\n",
            "Epoch 19/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.4589 - loss: 2.6617\n",
            "Epoch 20/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.5428 - loss: 2.4422\n",
            "Epoch 21/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.5851 - loss: 2.2497\n",
            "Epoch 22/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.6138 - loss: 2.0594\n",
            "Epoch 23/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.6569 - loss: 1.8786\n",
            "Epoch 24/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.7385 - loss: 1.7024\n",
            "Epoch 25/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.7677 - loss: 1.5375\n",
            "Epoch 26/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.7716 - loss: 1.5012\n",
            "Epoch 27/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 86ms/step - accuracy: 0.8241 - loss: 1.3233\n",
            "Epoch 28/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.8463 - loss: 1.1729\n",
            "Epoch 29/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 75ms/step - accuracy: 0.8677 - loss: 1.1129\n",
            "Epoch 30/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - accuracy: 0.8935 - loss: 0.9781\n",
            "Epoch 31/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.8988 - loss: 0.9196\n",
            "Epoch 32/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - accuracy: 0.8922 - loss: 0.8474\n",
            "Epoch 33/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.9152 - loss: 0.7544\n",
            "Epoch 34/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9240 - loss: 0.7051\n",
            "Epoch 35/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.9368 - loss: 0.6235\n",
            "Epoch 36/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - accuracy: 0.9422 - loss: 0.5791\n",
            "Epoch 37/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.9381 - loss: 0.5482\n",
            "Epoch 38/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.9527 - loss: 0.4952\n",
            "Epoch 39/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 0.9612 - loss: 0.4409\n",
            "Epoch 40/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9700 - loss: 0.4162\n",
            "Epoch 41/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.9709 - loss: 0.3693\n",
            "Epoch 42/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.9687 - loss: 0.3599\n",
            "Epoch 43/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - accuracy: 0.9736 - loss: 0.3302\n",
            "Epoch 44/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.9833 - loss: 0.3130\n",
            "Epoch 45/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - accuracy: 0.9839 - loss: 0.2877\n",
            "Epoch 46/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - accuracy: 0.9901 - loss: 0.2489\n",
            "Epoch 47/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - accuracy: 0.9844 - loss: 0.2473\n",
            "Epoch 48/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 0.9881 - loss: 0.2426\n",
            "Epoch 49/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.9866 - loss: 0.2120\n",
            "Epoch 50/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.9911 - loss: 0.2079\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e15ae8c1350>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "text='what are the future of machine learning'\n",
        "for i in range(10):\n",
        " token_text=tokenizer.texts_to_sequences([text])[0]\n",
        " paddedn_token_text=pad_sequences([token_text],maxlen=max_length-1,padding='pre')\n",
        " pos=np.argmax(model.predict(paddedn_token_text))\n",
        "\n",
        " for word,index in tokenizer.word_index.items():\n",
        "   if index==pos:\n",
        "     text=text+\" \"+word\n",
        "     print(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwK1YFH5EsTp",
        "outputId": "81e64302-af94-4df0-cf57-bd24923a5ac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "what are the future of machine learning and\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "what are the future of machine learning and deep\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "what are the future of machine learning and deep learning\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "what are the future of machine learning and deep learning is\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "what are the future of machine learning and deep learning is a\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "what are the future of machine learning and deep learning is a specific\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "what are the future of machine learning and deep learning is a specific subfield\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "what are the future of machine learning and deep learning is a specific subfield of\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "what are the future of machine learning and deep learning is a specific subfield of machine\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "what are the future of machine learning and deep learning is a specific subfield of machine learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HO-gyMBFFvzG",
        "outputId": "8763f08d-096a-4203-9610-a85455775500"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    }
  ]
}